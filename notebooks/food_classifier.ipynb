{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food classifier\n",
    "\n",
    "Dataset from ETH Zurich: [link](https://www.vision.ee.ethz.ch/datasets_extra/food-101/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path = pathlib.Path(r\"D:\\fastai\\food\")\n",
    "fname = dest_path/\"food-101.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This somehow seems broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_path = untar_data(url=URLs.FOOD, fname=fname, dest=dest_path); URLs.FOOD # http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So get the file manually, just download using your browser and move the file to where you want --> `fname`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tarfile.open(fname, \"r:gz\").extractall(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = dest_path/\"food-101/images\"; target_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads all available images. Which seems to be 1k per class (there are 101 classes). This is a lot! If you want to speed this up and are okay with a smaller sample of images skip the following cell and use the next code cell instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfms = get_transforms()\n",
    "# np.random.seed(42)\n",
    "# data = ImageDataBunch.from_folder(path=target_dir, train=\".\", valid_pct=.2, bs=32, ds_tfms=tfms, size=224).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsampling images to some smaller number using `n_img_per_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img_per_dir = 50 # number of images to select for each food dir\n",
    "img_dirs = [] #[\"nachos\", \"lobster_roll_sandwich\", \"ice_cream\", \"hummus\"]\n",
    "n_img_dirs = 2 if img_dirs is None or len(img_dirs)==0 else len(img_dirs) # if None then all are used. otherwise please choose an integer\n",
    "\n",
    "food_dirs = {_dir.name: _dir for _dir in target_dir.ls() if _dir.is_dir() if _dir.name != \"models\"}\n",
    "if isinstance(n_img_dirs, int) and ((img_dirs is None) or len(img_dirs)==0):\n",
    "    if n_img_dirs < len(food_dirs):\n",
    "        img_dirs = np.random.choice(list(food_dirs.keys()), size=n_img_dirs, replace=False)\n",
    "        \n",
    "food_dirs = {_name: food_dirs[_name] for _name in img_dirs}\n",
    "    \n",
    "food_fnames = {_food: np.random.choice([\"{}/{}\".format(_img.parent.name, _img.name) for _img in _dir.ls()], \n",
    "                                       size=n_img_per_dir, replace=False)\n",
    "               for _food, _dir in food_dirs.items()}\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"name\": np.concatenate([food_fnames[_food] for _food in sorted(food_fnames)]),\n",
    "    \"label\": np.concatenate([np.array([_food for _ in food_fnames[_food]]) for _food in sorted(food_fnames)])\n",
    "})\n",
    "\n",
    "print(\"# dirs\", len(food_dirs), \", \".join(food_dirs.keys()))\n",
    "print(\"# images\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "np.random.seed(42)\n",
    "data = ImageDataBunch.from_df(path=target_dir, df=df, valid_pct=.2, bs=32, ds_tfms=tfms, size=224).normalize(imagenet_stats)\n",
    "# data = ImageDataBunch.from_df(path=target_dir, df=df, valid_pct=.2, bs=8, ds_tfms=tfms, size=224).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"classes:\", data.classes)\n",
    "print(\"c\", data.c)\n",
    "print(\"num train\", len(data.train_ds))\n",
    "print(\"num valid\", len(data.valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet34, metrics=error_rate)\n",
    "# learn = cnn_learner(data, models.resnet50, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"stage-1-34\")\n",
    "# learn.save(\"stage-1-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(target_dir/\"export.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"stage-1-34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4, max_lr=slice(1e-6, 1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(ds_type=DatasetType.Train, rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(ds_type=DatasetType.Valid, rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fname = r\"strawberry_shortcake\\13097.jpg\" # r\"guacamole\\4541.jpg\" r\"strawberry_shortcake\\13097.jpg\"\n",
    "img = open_image(target_dir/img_fname)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2 = load_learner(path=target_dir, file=\"export.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2c = {i: c for c,i in learn2.data.c2i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class, pred_idx, probs = learn2.predict(img)\n",
    "topk = 2\n",
    "\n",
    "top_idx = torch.topk(probs, topk).indices\n",
    "print(\"pred_class\", pred_class)\n",
    "print(\"pred_idx\", pred_idx)\n",
    "\n",
    "print(\"\\nPredictions\")\n",
    "for _ix in top_idx.numpy():\n",
    "    print(\"\\t{} = {:.2f} %\".format(i2c[_ix], probs[_ix]*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37_fastai]",
   "language": "python",
   "name": "conda-env-py37_fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
