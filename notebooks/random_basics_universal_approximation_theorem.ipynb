{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random basics - universal approximation theorem\n",
    "\n",
    "Neural nets are highly flexible functions which can be used to approximate functions/relationships latent in a given data set. The explanation of this flexibility relates to the so-called _universal approximation theorem_. This was mentioned in one of fastai's lectures given by Jeremy Howard referring to the book by Michael Nielsen linked below. Do check it out, it's amazing.\n",
    "\n",
    "For reasons I wanted to implement something similar as in the book to play with various aspects beyond the concrete weights, more related to the used activation functions and so on. The idea is to set up some wild function which takes `x` and `y` and spits out `z` (so we can have a fancy 3d plots ðŸ˜¬) and fiddle with the network and optimization properties seing all the ways it can fail and those where it doe not. So let us have a look.\n",
    "\n",
    "**Things in this notebook**\n",
    "- ipywidgets-awesomeness for exploration\n",
    "- single neuron fit\n",
    "- multi neuron multi layer fit\n",
    "\n",
    "**Order of things**\n",
    "1. single neuron \n",
    "2. multi-multi\n",
    "\n",
    "**References**\n",
    "\n",
    "- Michael Nielsen, A visual proof that neural nets can compute any function, [chapter 4](http://neuralnetworksanddeeplearning.com/chap4.html), 2019 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a 2d surface with a single neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from typing import Union, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a simple plot using one of the standard activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1e3)\n",
    "dim = 2\n",
    "X = torch.zeros((n,dim))\n",
    "X[:,0].uniform_(-1, 1)\n",
    "X[:,1].uniform_(-1, 1)\n",
    "w = torch.ones(2)\n",
    "y = torch.tanh(X@w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting `y` (coloured circles) and \"`y_pred`\" (black dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa47d745bcf04ddb82b24da20112e33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='elev', max=180, min=-180), IntSlider(value=-55, descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotter_wrapper(X:torch.Tensor, y:torch.Tensor, y_pred:torch.Tensor=None, figsize=(10,10)):\n",
    "\n",
    "    def dynamic3d_scatter(elev=3, azim=-55):\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.gca(projection=\"3d\")\n",
    "        ax.scatter(X[:,0], X[:,1], zs=y , c=y, marker=\"o\", alpha=.5)\n",
    "        if y_pred is not None:\n",
    "            ax.scatter(X[:,0], X[:,1], zs=y_pred , c=\"k\", marker=\".\", alpha=.5)\n",
    "        ax.view_init(elev=elev, azim=azim)  # elev=20., azim=-55\n",
    "        plt.show()\n",
    "        \n",
    "    return dynamic3d_scatter\n",
    "\n",
    "dynamic3d_scatter = plotter_wrapper(X, y, y_pred=y)\n",
    "widgets.interact(dynamic3d_scatter, elev=(-180,180), azim=(-180,180));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the single neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lin): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, activation_fun:Union[str,callable]=\"relu\", dim_in:int=2, dim_out:int=1):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(dim_in, dim_out)\n",
    "        self.set_activation(activation_fun)\n",
    "        \n",
    "    def set_activation(self, fun_name):\n",
    "        if fun_name is None:\n",
    "            self.activation = lambda x: x\n",
    "        else:\n",
    "            self.activation = getattr(torch.nn.functional, fun_name) if isinstance(fun_name, str) else fun_name\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.lin(x)).squeeze(1)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "m = Model(activation_fun=None, dim_in=dim, dim_out=1)\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function mse_loss at 0x000001BA2F13DC18>\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.mse_loss\n",
    "opt = torch.optim.Adam(m.parameters(), lr=.01)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating away in the search of the global minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 0.0103182727470994\n",
      "gradient on the weights: tensor([[-0.0013, -0.0013]])\n",
      "\n",
      "loss: 0.01031816378235817\n",
      "gradient on the weights: tensor([[-0.0012, -0.0013]])\n",
      "\n",
      "loss: 0.010318048298358917\n",
      "gradient on the weights: tensor([[-0.0012, -0.0013]])\n",
      "\n",
      "loss: 0.010317926295101643\n",
      "gradient on the weights: tensor([[-0.0011, -0.0012]])\n",
      "\n",
      "loss: 0.010317795909941196\n",
      "gradient on the weights: tensor([[-0.0011, -0.0012]])\n",
      "\n",
      "loss: 0.010317650623619556\n",
      "gradient on the weights: tensor([[-0.0010, -0.0011]])\n",
      "\n",
      "loss: 0.010317495092749596\n",
      "gradient on the weights: tensor([[-0.0010, -0.0010]])\n",
      "\n",
      "loss: 0.010317327454686165\n",
      "gradient on the weights: tensor([[-0.0009, -0.0010]])\n",
      "\n",
      "loss: 0.010317150503396988\n",
      "gradient on the weights: tensor([[-0.0008, -0.0009]])\n",
      "\n",
      "loss: 0.010316967032849789\n",
      "gradient on the weights: tensor([[-0.0008, -0.0008]])\n",
      "\n",
      "loss: 0.010316782630980015\n",
      "gradient on the weights: tensor([[-0.0007, -0.0008]])\n",
      "\n",
      "loss: 0.01031660195440054\n",
      "gradient on the weights: tensor([[-0.0006, -0.0007]])\n",
      "\n",
      "loss: 0.010316433385014534\n",
      "gradient on the weights: tensor([[-0.0006, -0.0006]])\n",
      "\n",
      "loss: 0.010316275991499424\n",
      "gradient on the weights: tensor([[-0.0005, -0.0005]])\n",
      "\n",
      "loss: 0.010316138155758381\n",
      "gradient on the weights: tensor([[-0.0004, -0.0005]])\n",
      "\n",
      "loss: 0.010316023603081703\n",
      "gradient on the weights: tensor([[-0.0004, -0.0004]])\n",
      "\n",
      "loss: 0.010315928608179092\n",
      "gradient on the weights: tensor([[-0.0003, -0.0003]])\n",
      "\n",
      "loss: 0.010315856896340847\n",
      "gradient on the weights: tensor([[-0.0003, -0.0003]])\n",
      "\n",
      "loss: 0.010315803810954094\n",
      "gradient on the weights: tensor([[-0.0002, -0.0002]])\n",
      "\n",
      "loss: 0.010315771214663982\n",
      "gradient on the weights: tensor([[-0.0002, -0.0002]])\n",
      "\n",
      "loss: 0.010315751656889915\n",
      "gradient on the weights: tensor([[-0.0001, -0.0001]])\n",
      "\n",
      "loss: 0.010315744206309319\n",
      "gradient on the weights: tensor([[-6.9958e-05, -6.3570e-05]])\n",
      "\n",
      "loss: 0.010315747931599617\n",
      "gradient on the weights: tensor([[-2.9984e-05, -1.9549e-05]])\n",
      "\n",
      "loss: 0.010315753519535065\n",
      "gradient on the weights: tensor([[6.6815e-06, 2.0534e-05]])\n",
      "\n",
      "loss: 0.010315763764083385\n",
      "gradient on the weights: tensor([[4.0038e-05, 5.6671e-05]])\n",
      "\n",
      "loss: 0.010315774008631706\n",
      "gradient on the weights: tensor([[7.0126e-05, 8.8872e-05]])\n",
      "\n",
      "loss: 0.010315784253180027\n",
      "gradient on the weights: tensor([[9.6927e-05, 1.1720e-04]])\n",
      "\n",
      "loss: 0.01031579077243805\n",
      "gradient on the weights: tensor([[0.0001, 0.0001]])\n",
      "\n",
      "loss: 0.010315798223018646\n",
      "gradient on the weights: tensor([[0.0001, 0.0002]])\n",
      "\n",
      "loss: 0.01031580287963152\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315806604921818\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315804742276669\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315804742276669\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315801948308945\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315801948308945\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315796360373497\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315794497728348\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315792635083199\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315789841115475\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315786115825176\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315781459212303\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315775871276855\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315772145986557\n",
      "gradient on the weights: tensor([[0.0002, 0.0002]])\n",
      "\n",
      "loss: 0.010315767489373684\n",
      "gradient on the weights: tensor([[0.0001, 0.0001]])\n",
      "\n",
      "loss: 0.010315760038793087\n",
      "gradient on the weights: tensor([[0.0001, 0.0001]])\n",
      "\n",
      "loss: 0.010315755382180214\n",
      "gradient on the weights: tensor([[0.0001, 0.0001]])\n",
      "\n",
      "loss: 0.01031575072556734\n",
      "gradient on the weights: tensor([[0.0001, 0.0001]])\n",
      "\n",
      "loss: 0.010315744206309319\n",
      "gradient on the weights: tensor([[9.1961e-05, 9.3946e-05]])\n",
      "\n",
      "loss: 0.01031573861837387\n",
      "gradient on the weights: tensor([[7.8983e-05, 8.0555e-05]])\n",
      "\n",
      "loss: 0.010315736755728722\n",
      "gradient on the weights: tensor([[6.6268e-05, 6.7510e-05]])\n",
      "\n",
      "loss: 0.010315734893083572\n",
      "gradient on the weights: tensor([[5.3955e-05, 5.4897e-05]])\n",
      "\n",
      "loss: 0.010315733961760998\n",
      "gradient on the weights: tensor([[4.2143e-05, 4.2845e-05]])\n",
      "\n",
      "loss: 0.0103157302364707\n",
      "gradient on the weights: tensor([[3.0969e-05, 3.1447e-05]])\n",
      "\n",
      "loss: 0.010315732099115849\n",
      "gradient on the weights: tensor([[2.0496e-05, 2.0790e-05]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[1.0803e-05, 1.0922e-05]])\n",
      "\n",
      "loss: 0.0103157302364707\n",
      "gradient on the weights: tensor([[1.9851e-06, 1.9224e-06]])\n",
      "\n",
      "loss: 0.010315732099115849\n",
      "gradient on the weights: tensor([[-5.9935e-06, -6.2416e-06]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[-1.3044e-05, -1.3489e-05]])\n",
      "\n",
      "loss: 0.010315732099115849\n",
      "gradient on the weights: tensor([[-1.9212e-05, -1.9863e-05]])\n",
      "\n",
      "loss: 0.010315733961760998\n",
      "gradient on the weights: tensor([[-2.4462e-05, -2.5359e-05]])\n",
      "\n",
      "loss: 0.010315732099115849\n",
      "gradient on the weights: tensor([[-2.8841e-05, -2.9985e-05]])\n",
      "\n",
      "loss: 0.010315733030438423\n",
      "gradient on the weights: tensor([[-3.2392e-05, -3.3782e-05]])\n",
      "\n",
      "loss: 0.010315734893083572\n",
      "gradient on the weights: tensor([[-3.5119e-05, -3.6752e-05]])\n",
      "\n",
      "loss: 0.010315733961760998\n",
      "gradient on the weights: tensor([[-3.7116e-05, -3.8983e-05]])\n",
      "\n",
      "loss: 0.010315733030438423\n",
      "gradient on the weights: tensor([[-3.8438e-05, -4.0483e-05]])\n",
      "\n",
      "loss: 0.010315733030438423\n",
      "gradient on the weights: tensor([[-3.9093e-05, -4.1333e-05]])\n",
      "\n",
      "loss: 0.010315733961760998\n",
      "gradient on the weights: tensor([[-3.9163e-05, -4.1580e-05]])\n",
      "\n",
      "loss: 0.010315732099115849\n",
      "gradient on the weights: tensor([[-3.8747e-05, -4.1307e-05]])\n",
      "\n",
      "loss: 0.010315733961760998\n",
      "gradient on the weights: tensor([[-3.7887e-05, -4.0520e-05]])\n",
      "\n",
      "loss: 0.010315733030438423\n",
      "gradient on the weights: tensor([[-3.6631e-05, -3.9345e-05]])\n",
      "\n",
      "loss: 0.010315734893083572\n",
      "gradient on the weights: tensor([[-3.5062e-05, -3.7777e-05]])\n",
      "\n",
      "loss: 0.010315733030438423\n",
      "gradient on the weights: tensor([[-3.3220e-05, -3.5910e-05]])\n",
      "\n",
      "loss: 0.010315733961760998\n",
      "gradient on the weights: tensor([[-3.1192e-05, -3.3772e-05]])\n",
      "\n",
      "loss: 0.010315733961760998\n",
      "gradient on the weights: tensor([[-2.8974e-05, -3.1457e-05]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[-2.6641e-05, -2.8999e-05]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[-2.4232e-05, -2.6393e-05]])\n",
      "\n",
      "loss: 0.0103157302364707\n",
      "gradient on the weights: tensor([[-2.1784e-05, -2.3724e-05]])\n",
      "\n",
      "loss: 0.010315733030438423\n",
      "gradient on the weights: tensor([[-1.9330e-05, -2.1028e-05]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[-1.6896e-05, -1.8343e-05]])\n",
      "\n",
      "loss: 0.010315732099115849\n",
      "gradient on the weights: tensor([[-1.4523e-05, -1.5704e-05]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[-1.2236e-05, -1.3152e-05]])\n",
      "\n",
      "loss: 0.0103157302364707\n",
      "gradient on the weights: tensor([[-1.0038e-05, -1.0681e-05]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[-7.9152e-06, -8.3349e-06]])\n",
      "\n",
      "loss: 0.0103157302364707\n",
      "gradient on the weights: tensor([[-5.9020e-06, -6.1034e-06]])\n",
      "\n",
      "loss: 0.0103157302364707\n",
      "gradient on the weights: tensor([[-4.0398e-06, -3.9934e-06]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[-2.2753e-06, -2.0346e-06]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[-6.4541e-07, -2.2794e-07]])\n",
      "\n",
      "loss: 0.010315732099115849\n",
      "gradient on the weights: tensor([[8.0711e-07, 1.3788e-06]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[2.1256e-06, 2.8377e-06]])\n",
      "\n",
      "loss: 0.010315729305148125\n",
      "gradient on the weights: tensor([[3.3154e-06, 4.1053e-06]])\n",
      "\n",
      "loss: 0.0103157302364707\n",
      "gradient on the weights: tensor([[4.3687e-06, 5.2220e-06]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[5.2807e-06, 6.1442e-06]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[6.0227e-06, 6.9115e-06]])\n",
      "\n",
      "loss: 0.010315732099115849\n",
      "gradient on the weights: tensor([[6.6265e-06, 7.5243e-06]])\n",
      "\n",
      "loss: 0.0103157302364707\n",
      "gradient on the weights: tensor([[7.1276e-06, 7.9847e-06]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[7.4819e-06, 8.2836e-06]])\n",
      "\n",
      "loss: 0.010315732099115849\n",
      "gradient on the weights: tensor([[7.7275e-06, 8.4699e-06]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[7.8194e-06, 8.5307e-06]])\n",
      "\n",
      "loss: 0.0103157302364707\n",
      "gradient on the weights: tensor([[7.8374e-06, 8.4742e-06]])\n",
      "\n",
      "loss: 0.010315731167793274\n",
      "gradient on the weights: tensor([[7.7370e-06, 8.2967e-06]])\n"
     ]
    }
   ],
   "source": [
    "m.train()\n",
    "for i in range(n_iter):\n",
    "    y_pred = m(X)\n",
    "    l = loss(y, y_pred)\n",
    "    print(\"\\nloss:\", l.item())\n",
    "    l.backward()\n",
    "    print(\"gradient on the weights:\", m.lin.weight.grad)\n",
    "    opt.step()\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hah! The loss and the gradients of things actually decrease over time, promising! Let's have a look at what the model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fce908a379c4d5ea1d8af3bc532cf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='elev', max=180, min=-180), IntSlider(value=-55, descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.eval()\n",
    "y_pred = m(X).detach().numpy()\n",
    "dynamic3d_scatter = plotter_wrapper(X, y, y_pred=y_pred)\n",
    "widgets.interact(dynamic3d_scatter, elev=(-180,180), azim=(-180,180));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cram the model setup and fitting into a class so we can do things dynamically using `ipywidgets`.\n",
    "\n",
    "Note that sometimes the loss doesn't change at all. Suspect poor initialization but not sure yet. Just re-running the optimization usually fixes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAEWCAYAAADSL2tlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5xddZ3/8dd7apJJTyaFVEooAZIIk1AEFEWKNN1VirAoFlZdLIuuoq6ui+uuij9XXVkXLKtSBWxBUGCRKiCZQAgkISSEQIaEZNLLJFM/vz/OGbiMk+ROMjfnzsz7+Xjcx9x76ue23He+33O+RxGBmZmZmRWPkqwLMDMzM7M3ckAzMzMzKzIOaGZmZmZFxgHNzMzMrMg4oJmZmZkVGQc0MzMzsyLjgGa2j0iaKGmrpNICbPsiSfd093a7g6Tlkk7Juo6OJP2PpC/v4bpflPTj7q6pNyvmz6hZMXJAMyuQjsEkIl6OiIER0bqX250sKSSV5Wz7xog4dW+225tJ+oCkR3KnRcRHI+Jre7K9iPj3iPhw91SXP0njJf1K0lpJmyQ9I+kDOfMrJH1F0mJJ2yS9IukPkk7NWWa5pO2StkjaKOlRSR+VVNDfg46f0fQzfFAh9ynpa+lr1CLpq53Mf5+kl9LX6reShufMGy7pN+m8lyS9r5C1mnXkgGZmeyw3JNreyfO1vB5YAUwCRgCXAKtz5t8OnJtOHwbsD3wPOLPDds6OiEHpdr4BfB74yd7Uvy914XO3FPgccGcn2zgcuBb4O2A00AD8d84i1wBN6byLgB+m65jtGxHhm2++7eIGXAm8AGwBFgLv7jD/I8CinPlHkfyQtgHbga0kPxKTgQDKgAuA2g7b+Udgdnr/TOApYDPJD/JXc5Z7Od3O1vR2HPAB4JGcZY4H5gCb0r/H58x7APga8Oe05nuAkXm+Fm8F6kh+0F8Frk+nnwXMAzYCjwLTctZZDpyS3v8Z8G8dt9eF9+IjJD+664HZwH458wL4JLAMWAtcTfKf0MOAHUBr+npt7FhLzvP6HLAGWAW8C3gn8Hy6vy/m7OurwA3p/R/kvBdbgZb29wvYD/gVUA+8CHyywzZuB25I3+cP5/H8twIzdjLvFJLP2/jdbOO19yNn2iySz+sReb4PAXwUWAJsIAkz2s06r31GgYfSbWxLn9P5eX6OPg/MBxqBsi58bm4g5zuUTvt34KacxweSBLJBQFV6/+Cc+dcD3+juf198821nN7egme3eC8CJwBDgX4EbJI0FkPRekh/aS4DBwDnAuoj4O5IgdXYk3Zrf6rDN2cAhkqbkTHsfcFN6f1u6zaEkYe1jkt6Vzjsp/Ts03fZjuRtOu2nuBL5P0sryHeBOSSM67OtSYBRQAXw2Z/35u+nOGQMMJ2l9uUzSUcBPgb9P93ctMFtS5S620WWS3gb8B3AeMBZ4Cbilw2LvBmpIQvK5wAcjYhFJmHgsfb2G7uJ59QPGAV8BfgRcDBxN8v5/RdIBHVeKiMvT7Q4ETiAJLL9LuwzvAJ5Ot/l24NOSTstZ/VySkDYUuFHSCZI27uJleBy4RtIFkiZ2mHcK8JeIqNvF+p2KiCdIAuqJXVjtLGAmMJ3kPTlt14u/YX/tn+Hp6Wv3yzw/RxeSfB+GRkSLpP+W9N/smcNJ3pv2ml4gDWXprTUins9Z/ul0HbN9wgHNbDci4raIWBkRbRHxS5JWg1np7A8D34qIOZFYGhEv5bHNBuB3JD84pEHtUJLgRkQ8EBHPpPucD9wMvCXPks8ElkTE9RHREhE3A88BZ+cs878R8XxEbAduBWbk1DYtIm5i59qAf4mIxnT9jwDXRsRfIqI1In5O0sJxbJ715usi4KcR8WRENAJfAI6TNDlnmW9GxPqIeBn4Lunrm6dm4OsR0UwS/EYC34uILRGxAFgATNvZypKqgd8Cn4iIp0jCS3VEXBURTRGxjCT0XZCz2mMR8dv0fd4eEY/sIkACvBd4GPgy8KKkeZJmpvNGkrRqttczPD3GbJOkHXk8/5UkwTtf34iIjelrfT85n6E9lM/n6PsRsSL93BERH4+Ij+/h/gaStDDn2kTSgrareWb7hAOa2W5IuiT9IdyYtm4cQfJjCDCBpIVtT9zE6wHifcBv0+CGpGMk3S+pXtImkhagkTvZTkf7kbQu5XqJpBWn3as59xtIfpDyVR8RuT/4k4DPtL8+6Ws0Ia2jO73heUXEVmAdb3xeK3Luv9TFGtbF6ydwbE//5h7ftZ2dvE6Syklawm6KiPZWvUnAfh1ely+SHNPUWb27FREbIuLKiDg83c484LeSRPJajM1Zdn0a9o4G8mnNHEfSlZuvvfkMdSafz1GXXq/d2ErS6p1rMEm3/67mme0TDmhmuyBpEkmrx+XAiPQH71lA6SIrSI5d6UzsZvP3ACMlzSAJarmtVjeRtKZNiIghwP/k7HN3211J8mOXayLwym7Wy1fH/a8gaXkamnMbkLbcdbQNGJDzeEwX9vuG5yWpiqQrLPd5Tci5PzFdp7Oau9t/kfx4/3POtBXAix1el0ER8c6cZfa4rohYC3ybJMAMB+4DZkoa39Vtpa1w44BHdrdsAeXzOerO93EBSfcsAGn3dSXJMYfPA2UdDkGYnq5jtk84oJntWhXJj0I9gKRLSVrQ2v0Y+Kyko5U4KA11kLS+/NUxS+0iooWk1eVqkh/Ye3NmDwLWR8QOSbNIWtja1ZN0M+5s23cBB6dDCJRJOh+YCvw+r2fcdT8CPpq2+klSlaQzJXXWHTQPeGfa/TYG+HTuTEk/k/SzneznJuBSSTPS45L+neSYq+U5y/yTpGGSJgCfAn6ZTl8NjJdUscfPcick/T1J9/P7IqItZ9YTwGZJn5fUX1KppCNyuiT3ZF/fTLdRlr6+HwOWRsS6iLiHpKvxt+l7UZG27O20q1nSYElnkXTp3hARz6TTPyBp+Z7WmaeO34+ufI7yIqlcUj+S37oySf30+jiENwJnSzoxDftXAb9Ou7S3Ab8GrkrreDPJ8YLX72ktZl3lgGa2CxGxEPh/wGMkPyhHkpz92D7/NuDrJOFhC8kxSO3H8fwH8M9pd81n6dxNJAd335YGtnYfJ/lx2EJywPqtOftsSPf553Tbb/gBjoh1JAdwf4ak2+tzwFlpi8tuSVog6aJ8lk33V0ty/NAPSA6QX0pyxl5nric52Ho5SQviLzvMn0DO69thP/eRHHv1K5KzLA/kjcdzQXJc31ySIHgnrw8d8SeS1o9XJeX1OnTBhSRBY6WSgYi3Svpi2l16NsmxWS+SnFn6Y5KTTTqVhoWtu9jXAOA3JGc5LiNpUTwnZ/7fkATxG9JlXiQ5du/0Dtu5I/1srQC+RHIiyaU583f6PnSjrwI/Tz/D53XxcwS8Ntjw/+xikR+RdE1fSPI8t5MMq0F6XOFHSYLaGpL/FOUez/ZxoH8672bgY+k6ZvuEIgrd8m9mtntp69bTJEMrNO/B+gFMiYil3V5cH6NkxP9PpWfAmlkGHNDMrFdwQDOz3sRdnGZm1i3SLsetndx21Q1pZp1wC5qZmZlZkXELmpmZmVmRKfiFjiWdTnKx3lLgxxHxjQ7zryAZjb2FZPiAD+aOxC5pMMl1Dn8TEZfval8jR46MyZMnd+8TMDMzMyuAuXPnro2I6s7mFTSgpePNXAO8g+Q6b3MkzU6HLmj3FFATEQ2SPgZ8Czg/Z/7XgAfz2d/kyZOpra3tnuLNzMzMCkjSTi8NWOguzlkkgygui4gmksEQz81dICLub7+8DcmFgF8bBVvS0SSXM7mnwHWamZmZFY1CB7RxvPHaaXW88bp5HX0I+AOApBKSAUL/aVc7kHSZpFpJtfX19XtZrpmZmVn2Ch3Q1Mm0Tk8blXQxUENy2RtIRnG+KyJ2eXHciLguImoioqa6utNuXDMzM7MepdAnCdTxxosXj+f1ixe/RtIpJJfheEtENKaTjwNOlPRxYCBQIWlrRFxZ4JrNzMzMMlXogDYHmCJpf+AVkuvm5V70GUlvAq4FTo+INe3TI+KinGU+QHIigcOZmZmZ9XoF7eJML/58OXA3yVAZt0bEAklXSWq/wO/VJC1kt0maJ2l2IWsyMzMzK3a96koCNTU14WE2zMzMrCeQNDciajqbV/CBanuTiODb9yxmQEUZAyvLGFBRysDKMqoqyzh49CDGDOmXdYlmZmbWCzigdcH25lb+58FltLZ13up4yOhBvOWQak6aUs3M/YdRWVa6jys0MzOz3sBdnF0UETS2tLGtsYVtja1sa2ph8/Zm5q3YyIPP11O7fANNrW30Ly/lnOn78cV3HsaQAeUFrcnMzMx6nl11cTqgdbNtjS08vmwd/7doDbfWrmB4VQVff9cRnHr4mEzrMjMzs+Kyq4BW6IFq+5yqyjLeftho/uNvjuR3//BmRg6s5LLr5/KJm59i3dbG3W/AzMzM+jwHtAI6YtwQfvcPb+aKdxzMH59dxTv+8yHuXvBq1mWZmZlZkXNAK7CKshI++fYp/P4TJzJuaH8+fuOTPLB4ze5XNDMzsz7LAW0fOWTMIG6+7FgOGT2If7jxSRau3Jx1SWZmZlakHND2oYGVZfz0AzMZ1K+cD/5sDq9u2pF1SWZmZlaEHND2sTFD+vG/l85ka2MLl/5sDlsbW7IuyczMzIqMA1oGDhs7mGsuOornV2/h8puepKW1LeuSzMzMrIg4oGXkLQdX87Vzj+CBxfX86x0Lsy7HzMzMiogDWobed8xEPnLi/lz/+Es8vmxd1uWYmZlZkXBAy9hnTj2EcUP7c9UdC3d6jU8zMzPrWxzQMtavvJQrzziUhas2c/vcFVmXY2ZmZkXAAa0InDVtLDWThnH13YvZsqM563LMzMwsYw5oRUASXzl7Kmu3NnHN/S9kXY6ZmZllrOABTdLpkhZLWirpyk7mXyFpoaT5ku6TNCmdPknSXEnzJC2Q9NFC15qlaeOH8rdHjeenj7zIS+u2ZV2OmZmZZaigAU1SKXANcAYwFbhQ0tQOiz0F1ETENOB24Fvp9FXA8RExAzgGuFLSfoWsN2ufO/0QykrFf9z1XNalmJmZWYYK3YI2C1gaEcsiogm4BTg3d4GIuD8iGtKHjwPj0+lNEdGYTq/cB7VmbvTgfnz8rQfyxwWv8tgLHnbDzMysryp06BkH5J6aWJdO25kPAX9ofyBpgqT56Ta+GRErO64g6TJJtZJq6+vru6ns7Hz4xAOSYTd+72E3zMzM+qpCBzR1Mq3T1CHpYqAGuPq1BSNWpF2fBwHvlzT6rzYWcV1E1ERETXV1dTeVnZ1+5aV87vRDWLRqMw8sXpN1OWZmZpaBQge0OmBCzuPxQGetYKcAXwLOyenWfE3acrYAOLFAdRaVdx45ltGDK/n5Yy9lXYqZmZlloNABbQ4wRdL+kiqAC4DZuQtIehNwLUk4W5Mzfbyk/un9YcCbgcUFrrcolJeWcNExk3jo+XpeqN+adTlmZma2jxU0oEVEC3A5cDewCLg1IhZIukrSOeliVwMDgdvSITXaA9xhwF8kPQ08CHw7Ip4pZL3F5MJZE6koLeF6t6KZmZn1OWWF3kFE3AXc1WHaV3Lun7KT9e4FphW2uuJVPaiSM6eN5fa5dXz2tEMYWFnwt8rMzMyKRK8fuqInu+S4SWxtbOHXT9ZlXYqZmZntQw5oRexNE4cxffwQfv7ociI85IaZmVlf4YBW5N5//GReqN/Gn5d64FozM7O+wgGtyJ05bSwjqir42aPLsy7FzMzM9hEHtCJXWVbKhbMmct9zq1mxvmH3K5iZmVmP54DWA1x07ERKJG543ENumJmZ9QUOaD3A2CH9Oe3w0dwyZwXbm1qzLsfMzMwKzAGth7j42Els2t7MvYtWZ12KmZmZFZgDWg9x7P4jGD24kjue/qtLmZqZmVkv44DWQ5SUiDOP3I8HF9ezaXtz1uWYmZlZATmg9SBnTx9LU2sb9y50N6eZmVlv5oDWg8yYMJTxw/q7m9PMzKyXc0DrQSRx1rT9eGTpWtZva8q6HDMzMysQB7Qe5uzpY2ltC/747KtZl2JmZmYF4oDWw0wdO5gDqqvczWlmZtaLOaD1MO3dnI+/uI41m3dkXY6ZmZkVgANaD3T2tLFEwF3PrMq6FDMzMyuAggc0SadLWixpqaQrO5l/haSFkuZLuk/SpHT6DEmPSVqQzju/0LX2FFNGD+LQMYO4Y74DmpmZWW9U0IAmqRS4BjgDmApcKGlqh8WeAmoiYhpwO/CtdHoDcElEHA6cDnxX0tBC1tuTnD19P+a+tIG6DQ1Zl2JmZmbdrNAtaLOApRGxLCKagFuAc3MXiIj7I6I9ZTwOjE+nPx8RS9L7K4E1QHWB6+0xzpo2FoA73YpmZmbW6xQ6oI0DVuQ8rkun7cyHgD90nChpFlABvNDJvMsk1Uqqra+v38tye45JI6qYPn4Iv3dAMzMz63UKHdDUybTodEHpYqAGuLrD9LHA9cClEdH2VxuLuC4iaiKiprq6bzWwnT19P555ZRMvrt2WdSlmZmbWjQod0OqACTmPxwN/NYCXpFOALwHnRERjzvTBwJ3AP0fE4wWutcc548ikm/OeBR601szMrDcpdECbA0yRtL+kCuACYHbuApLeBFxLEs7W5EyvAH4D/CIibitwnT3SuKH9OWzsYO57bs3uFzYzM7Meo6ABLSJagMuBu4FFwK0RsUDSVZLOSRe7GhgI3CZpnqT2AHcecBLwgXT6PEkzCllvT/T2Q0cx96UNbGpozroUMzMz6yZlhd5BRNwF3NVh2ldy7p+yk/VuAG4obHU938mHjuIH9y/lwSX1nDN9v6zLMTMzs27gKwn0cDMmDGV4VQV/WrQ661LMzMysmzig9XClJeKth1TzwPP1tLZ1eoKsmZmZ9TAOaL3A2w4dxcaGZp56eUPWpZiZmVk3cEDrBU6cUk1ZiXw2p5mZWS/hgNYLDOlfzszJw/nTIgc0MzOz3sABrZd426GjWLx6iy+ebmZm1gs4oPUSbztsFAD3u5vTzMysx3NA6yUOGFnF5BEDfByamZlZL+CA1ktI4uRDR/HoC+toaGrJuhwzMzPbCw5ovcjbDx1NU0sbjy5dl3UpZmZmthcc0HqRWfsPp6qi1N2cZmZmPZwDWi9SUVbCSQdX86fnVhPhqwqYmZn1VA5ovczJh45i9eZGFqzcnHUpZmZmtocc0HqZkw9Jhtt4YLG7Oc3MzHqqvAKapDdLqkrvXyzpO5ImFbY02xPVgyqZOnYwDy9Zm3UpZmZmtofybUH7IdAgaTrwOeAl4BcFq8r2yolTRvLkyxvY1ujhNszMzHqifANaSyRHnZ8LfC8ivgcMKlxZtjdOmDKS5tbgiRfXZ12KmZmZ7YF8A9oWSV8ALgbulFQKlOezoqTTJS2WtFTSlZ3Mv0LSQknzJd2X23Uq6Y+SNkr6fZ51GjBz8nAqykrczWlmZtZD5RvQzgcagQ9FxKvAOODq3a2UBrlrgDOAqcCFkqZ2WOwpoCYipgG3A9/KmXc18Hd51mipfuWlzJo8nEeW1mddipmZme2BvFvQSLo2H5Z0MDADuDmP9WYBSyNiWUQ0AbeQdJO+JiLuj4iG9OHjwPicefel+7YuOmHKSJ5fvZXVm3dkXYqZmZl1Ub4B7SGgUtI44D7gUuBneaw3DliR87gunbYzHwL+kGdNAEi6TFKtpNr6ercYtTvhoJEA/HmpuznNzMx6mnwDmtJWrr8B/isi3g0cns96nUzrdIh7SRcDNeTRdfqGjUVcFxE1EVFTXV3dlVV7taljBzO8qoJHfByamZlZj5N3QJN0HHARcGc6rTSP9eqACTmPxwMrO9n4KcCXgHMiojHPmmwXSkrE8QeO4JGla33ZJzMzsx4m34D2aeALwG8iYoGkA4D781hvDjBF0v6SKoALgNm5C0h6E3AtSTjz8Pfd6MQpI1mzpZHnV2/NuhQzMzPrgrJ8FoqIB4EHJQ2SNDAilgGfzGO9FkmXA3eTtLj9NA14VwG1ETGbpEtzIHCbJICXI+IcAEkPA4cCAyXVkZxFenfXn2bfdMKUpMv34SX1HDLGw9aZmZn1FHkFNElHklw5YHjyUPXAJRGxYHfrRsRdwF0dpn0l5/4pu1j3xHzqs86NG9qfA0ZW8cjStXz4xAOyLsfMzMzylG8X57XAFRExKSImAp8BflS4sqy7nDBlJH9Ztp7GltasSzEzM7M85RvQqiLitWPOIuIBoKogFVm3OuGgkWxvbuXJlzZmXYqZmZnlKd+AtkzSlyVNTm//DLxYyMKsexx74AhKS+SrCpiZmfUg+Qa0DwLVwK+B36T3Ly1UUdZ9BvcrZ8aEoTyydF3WpZiZmVme8j2LcwN5nLVpxemEg0byX39awqaGZoYMyOsa92ZmZpahXQY0SXewk5H/AdqHw7DiduKUkXzvviU8+sJazjhybNblmJmZ2W7srgXt2/ukCiuo6ROGMrCyjIeXOqCZmZn1BLsMaOkAtbsl6VcR8bfdU5J1t/LSEo49YDiP+sLpZmZmPUK+JwnsjkdBLXLHHziS5esaqNvQkHUpZmZmthvdFdB8Ne4id8KUkQA86rM5zczMil53BTQrclNGDaR6UCWPuJvTzMys6HVXQFM3bccKRBJvPnAEj76wlgg3eJqZmRWzvAOapP6SDtnJ7M93Uz1WQMcfNJK1W5tYvHpL1qWYmZnZLuQV0CSdDcwD/pg+niFpdvv8iLinMOVZd3rzQclxaI8scTenmZlZMcu3Be2rwCxgI0BEzAMmF6YkK5RxQ/tzwMgqHn3BJwqYmZkVs3wDWktEbCpoJbZPHH/QCP6ybB3NrW1Zl2JmZmY7kW9Ae1bS+4BSSVMk/RfwaAHrsgI54aCRbGtq5ekVG7MuxczMzHYi34D2CeBwoBG4GdgMfDqfFSWdLmmxpKWSruxk/hWSFkqaL+k+SZNy5r1f0pL09v48a7VdOPaAEUh4uA0zM7MilldAi4iGiPhSRMwEjgG+GRE7dreepFLgGuAMYCpwoaSpHRZ7CqiJiGnA7cC30nWHA/+S7m8W8C+ShuX3tGxnhg6o4MhxQzxgrZmZWRHL9yzOmyQNllQFLAAWS/qnPFadBSyNiGUR0QTcApybu0BE3B8R7dcfehwYn94/Dbg3ItZHxAbgXuD0fOq1XTv+wJE8+fIGtjW2ZF2KmZmZdSLfLs6pEbEZeBdwFzAR+Ls81hsHrMh5XJdO25kPAX/oyrqSLpNUK6m2vr4+j5LshING0tIWPPHi+qxLMTMzs07kG9DKJZWTBLTfRUQz+V1/s7MrDHS6nqSLgRrg6q6sGxHXRURNRNRUV1fnUZLVTB5GRVkJf/ZxaGZmZkUp34B2LbAcqAIeSg/k35zHenXAhJzH44GVHReSdArwJeCciGjsyrrWdf3KS6mZNMwnCpiZmRWpfE8S+H5EjIuId0biJeDkPFadA0yRtL+kCuACYHbuApLeRBIAz4mINTmz7gZOlTQsPTng1HSadYM3HzSS517dwtqtjbtf2MzMzPapfE8SGCrpk5K+I+n7kr4PfGd360VEC3A5SbBaBNwaEQskXSXpnHSxq4GBwG2S5rVfQioi1gNfIwl5c4Cr0mnWDdov++SrCpiZmRWfsjyXu4vkDMtngC4NQR8Rd6Xr5077Ss79U3ax7k+Bn3Zlf5afI8cNYVC/Mv68ZC3nTN8v63LMzMwsR74BrV9EXFHQSmyfKi0Rxx84gkeWriUikDo7J8PMzMyykO9JAtdL+oiksZKGt98KWpkV3EkHV/PKxu28UL8t61LMzMwsR74BrYnkWLHHgLnprbZQRdm+cdKUZFiSh5d4/DgzM7Nikm9AuwI4KCImR8T+6e2AQhZmhTdh+AD2H1nFQ887oJmZmRWTfAPaAqBht0tZj3PilJE8vmw9jS2tWZdiZmZmqXwDWiswT9K17cNspENtWA930pRqtje3Mnf5hqxLMTMzs1S+Z3H+Nr1ZL3PcgSMoLxUPLqnn+HRsNDMzM8tWXgEtIn5e6EIsG1WVZRw1cRgPP7+WL5yRdTVmZmYG+XdxWi920sHVLFy1mfotvuyTmZlZMXBAMw+3YWZmVmQc0IzD9xvM8KoKHl6yNutSzMzMjC4ENEmX7eqx9VwlJeKEg0by8JJ62toi63LMzMz6vK60oHW8WKMv3tiLnHRwNWu3NrHo1c1Zl2JmZtbn5R3QIuLaXT22nu2kKckQGw89725OMzOzrOUV0CR9StJgJX4i6UlJpxa6ONt3Rg3ux6FjBvmyT2ZmZkUg3xa0D0bEZuBUoBq4FPhGwaqyTJx0cDW1L62noakl61LMzMz6tHwDWvvxZu8E/jcinibPY9AknS5psaSlkq7sZP5JaYtci6T3dJj3TUnPprfz86zV9tCJU0bS3Bo8vmxd1qWYmZn1afkGtLmS7iEJaHdLGgS07W4lSaXANcAZwFTgQklTOyz2MvAB4KYO654JHAXMAI4B/knS4DzrtT0wc/JwKstKfByamZlZxvINaB8CrgRmRkQDUE7Szbk7s4ClEbEsIpqAW4BzcxeIiOURMZ+/DnxTgQcjoiUitgFPA6fnWa/tgX7lpRxzwAgeWLyGCA+3YWZmlpV8A9pxwOKI2CjpYuCfgU15rDcOWJHzuC6dlo+ngTMkDZA0EjgZmJDnuraH3nHYKJava2Dpmq1Zl2JmZtZn5RvQfgg0SJoOfA54CfhFHut1dpxaXk0zEXEPcBfwKHAz8BjwV0evS7pMUq2k2vp6n4G4t94xdQwAdy94NeNKzMzM+q58A1pLJH1e5wLfi4jvAYPyWK+ON7Z6jQdW5ltcRHw9ImZExDtIwt6STpa5LiJqIqKmuro6303bTowZ0o8ZE4Zy94LVWZdiZmbWZ+Ub0LZI+gLwd8Cd6cH/5XmsNweYIml/SRXABcDsfHYoqVTSiPT+NGAacE+e9dpeOO3wMTzzyiZe2bg961LMzMz6pHwD2vlAI8l4aK+SHEd29e5WiogW4HLgbmARcGtELJB0laRzACTNlFQHvBe4VtKCdPVy4GFJC4HrgIvT7VmBnXr4aADucTenmZlZJpTv2XqSRgMz04dPRMSaglW1h2pqaqK2tjbrMnqFU77zICMHVnDLZcdlXYqZmVmvJKcXp+YAABaeSURBVGluRNR0Ni/fSz2dBzxB0sp1HvCXjoPKWu9y2uGjeeLF9WzY1pR1KWZmZn1Ovl2cXyIZA+39EXEJyfhmXy5cWZa10w4fQ1vA/y3yyQJmZmb7Wr4BraRDl+a6LqxrPdCR44aw35B+PpvTzMwsA2V5LvdHSXeTjEcGyUkDdxWmJCsGkjj18DHc/MTLNDS1MKAi34+KmZmZ7a28WsEi4p9IzqScBkwHrouIzxeyMMveqVNH09jSxoOLPQCwmZnZvpR3s0hE/Ar4VQFrsSIza//hDB1Qzj0LV3PGkWOzLsfMzKzP2GVAk7SFzi/NJCAiYnBBqrKiUFZawtsPHc29C1+lubWN8lIfdmhmZrYv7PIXNyIGRcTgTm6DHM76htMOH83mHS08vmxd1qWYmZn1GW4SsV066eBq+peX+uLpZmZm+5ADmu1Sv/JS3nJwNfcsWE1La1vW5ZiZmfUJDmi2W+96036s2dLIAz6b08zMbJ9wQLPdevthoxk1qJIb//JS1qWYmZn1CQ5otlvlpSVcMHMCDzxfz4r1DVmXY2Zm1us5oFlezp81EQG3zHk561LMzMx6PQc0y8u4of1526Gj+OWcFTS1+GQBMzOzQnJAs7xddOwk1m5t4p6FHnLDzMyskBzQLG8nTalm/LD+3Pi4uznNzMwKqeABTdLpkhZLWirpyk7mnyTpSUktkt7TYd63JC2QtEjS9yWp0PXazpWWiAtnTeSxZetYumZr1uWYmZn1WgUNaJJKgWuAM4CpwIWSpnZY7GXgA8BNHdY9HngzMA04ApgJvKWQ9drunVczgbIScfMTbkUzMzMrlEK3oM0ClkbEsohoAm4Bzs1dICKWR8R8oOOR5wH0AyqASqAcWF3gem03qgdVctoRY7h9bh07mluzLsfMzKxXKnRAGwesyHlcl07brYh4DLgfWJXe7o6IRR2Xk3SZpFpJtfX1Hul+X7jomIls2t7MnfNXZV2KmZlZr1TogNbZMWOR14rSQcBhwHiSUPc2SSf91cYirouImoioqa6u3qtiLT/HHTCCA0ZW+coCZmZmBVLogFYHTMh5PB5Ymee67wYej4itEbEV+ANwbDfXZ3tAEhcfO4knX97Iw0vcamlmZtbdCh3Q5gBTJO0vqQK4AJid57ovA2+RVCapnOQEgb/q4rRsvO+YiUweMYCv/G6Bj0UzMzPrZgUNaBHRAlwO3E0Srm6NiAWSrpJ0DoCkmZLqgPcC10pakK5+O/AC8AzwNPB0RNxRyHotf/3KS7nq3CN4ce02rntoWdblmJmZ9SqKyOuQsB6hpqYmamtrsy6jT/mHm57k3oWrufcfT2LSiKqsyzEzM+sxJM2NiJrO5vlKArZXvnzmVMpLxFdnL6A3hX0zM7MsOaDZXhkzpB9XnHoI9y+u5+4FvkanmZlZd3BAs732/uMmceiYQfzrHQvZ1tiSdTlmZmY9ngOa7bWy0hK+/u4jWLVpB9+/b0nW5ZiZmfV4DmjWLY6eNJwLZk7gJ4+8yB+e8RUGzMzM9oYDmnWbL5xxGEeOH8LHbnyS/7z3edrafNKAmZnZnnBAs24zZEA5N3/kWN5z9Hi+d98SPnbjXB+TZmZmtgfKsi7Aepd+5aVc/Z5pHDpmEP9+1yL+9oeP8qNLapgwfEBe60cEK9ZvZ17dRp5esZH5dRvZsqOFqsoyBlSUUlVRxoDKUg4dM4j3HTOJgZX+CJuZWe/jgWqtYB56vp7Lb3qSkhJx2tQxHDZ2EIeOHcxhYwYzZEA5za1tLKvfxqJVm1m0ajMLV23m2Vc2saGhGYDKshKOGDeE4VUVNDS1sK2xlYamFrbuaGHlph0Mr6rgspMO4JLjJjGgwkHNzMx6ll0NVOuAZgX14tptXHXHAp6u28T6bU2vTR89uJIN25ppam0DoKK0hINGDeTIcUOYPmEo08YP4ZAxgygv7bwXft6Kjfznvc/z4PP1jBxYwUffciAXHTOJ/hWl++R5mZmZ7S0HNMtcRLBmS2PaWraFJWu2UD2wksPGDuawsYM5oLpqp2FsV+a+tIHv/t/zPLxkLeOH9eemDx/LxBH5daeamZllyQHNer1HX1jLx298kqqKMm657Ni8j3kzMzPLiq/Fab3e8QeO5IYPHcPWxhYuuO5xVqxvyLokMzOzPeaAZr3GEeOGcOOHHdLMzKznc0CzXsUhzczMegMHNOt1ckPahT96/A1nj5qZmfUEDmjWKx0xbgi/+OAs1mxu5LO3PU1vOhnGzMx6v4IHNEmnS1osaamkKzuZf5KkJyW1SHpPzvSTJc3Lue2Q9K5C12u9x/QJQ/nSmYfxp+fW8JNHXsy6HDMzs7wVNKBJKgWuAc4ApgIXSpraYbGXgQ8AN+VOjIj7I2JGRMwA3gY0APcUsl7rfS45bhKnTh3NN//4HE+v2Jh1OWZmZnkpdAvaLGBpRCyLiCbgFuDc3AUiYnlEzAfadrGd9wB/iAgf8W1dIolvvWcaowb14xM3P8XmHc1Zl2RmZrZbhQ5o44AVOY/r0mlddQFwc2czJF0mqVZSbX19/R5s2nq7oQMq+P6FM3hl43a++OtnfDyamZkVvUIHNHUyrUu/jpLGAkcCd3c2PyKui4iaiKiprq7egxKtLzh60nCueMfB/H7+Km6Zs2L3K5iZmWWo0AGtDpiQ83g8sLKL2zgP+E1EuG/K9srH3nIgJ04ZyVdnL2DJ6i1Zl2NmZrZThQ5oc4ApkvaXVEHSVTm7i9u4kJ10b5p1RUmJ+H/nTaeqsoxP/3IeTS27OuzRzMwsOwUNaBHRAlxO0j25CLg1IhZIukrSOQCSZkqqA94LXCtpQfv6kiaTtMA9WMg6re8YNagf//E3R7Jg5Wa++3/PZ12OmZlZp8oKvYOIuAu4q8O0r+Tcn0PS9dnZusvZs5MKzHbqtMPHcF7NeP7nwRc4+dBRzJw8POuSzMzM3sBXErA+6StnH874YQO44tZ5bPHQG2ZmVmQc0KxPGlhZxnfOm84rG7Zz1R0Lsy7HzMzsDRzQrM+qmTycj731QG6bW8cfn30163LMzMxe44Bmfdqn3n4wR4wbzBd+PZ81m3dkXY6ZmRnggGZ9XEVZCd89fwbbm1u5/KanaG710BtmZpY9BzTr8w4aNYhv/u00nli+nn+/a1HW5ZiZmRV+mA2znuDcGeOYt2Ij//vn5cyYMJRzZ3h0FzMzy45b0MxSX3znYcyaPJzP/2o+i1ZtzrocMzPrwxzQzFLlpSX84KI3MbhfOR+9YS6btnt8NDMzy4YDmlmOUYP68cOLj+KVDdu54pfzaGuLrEt6g5bWNhqaWtjY0MSazTuo29BAQ1NL1mWZmVk38zFoZh0cPWk4Xz5rKv8yewFf+PUz/Nu7j6C8dN/+X2ZHcyvPvbqFZ1/ZxIKVm3j2lc0sXr1lpxd4HzagnP2G9me/of0ZN7Q/B48exPQJQzhk9CDK9nHtZma29xzQzDpxyXGTqN/SyA/uX8orG7dzzUVHMaR/eUH3uamhmbsXvsqd81fx56VraUlb74b0L+eIcYO55NhJDO5fTkVZCZVlJVSUlVBWItZta2Llxu2s3LiDl9c18NgL69jamLSq9Ssv4Yj9hjBt/FCOmjSUmZOHM3pwv4I+DzMz23uKKK4unL1RU1MTtbW1WZdhvchttSv44m+eYdKIKn76/plMHDGgW7e/ZUczf3z2Ve58ZhWPLElC2YTh/Tn98DEcPWkYh+83hPHD+iMp721GBCvWb2de3UaeXrGR+XUbeeaVTexoTlrfJgzvz8xJw6mZPJyjJw3joFEDKS3Jf/tmZtY9JM2NiJpO5zmgme3aYy+s46M3zKWsRFx3ydEcPWn4Xm0vInjixfX8snYFdz2zih3NbYwb2p+zpo3lzGljOXLckC4Fsny0tLaxcNVm5izfQO3y9cxZvp61W5sA6F9eyhHjBjNt/FCmjR/C4fsNZuLwKirK3DVqZlZIDmhme+mF+q188GdzWLVpB5effBDnz5zQ5a7CFesbmP30Sm6rXcHydQ0MrCzj7On78Z6jx3PUxKHdHsp2JSJYvq6BeSs28PSKTcyv28iClZtpTI9xKxGMG9afySOq2H9kFROHD6B6UCXDqyoYUVXJyIEVDKuq2OfH5pmZ9SYOaGbdYP22Jj5z6zzuX1xPieDkQ0Zx/swJnHzoqE6DSlNLG7XL13P/4jX86bk1vFC/DYBj9h/OeTUTOOPIMQyoKJ7DQFta23h+9Vaee3Uzy9du48V1DSxfu43la7expbHzM0UrykoYUFFKVUUZ/StKGVBRSr+yUirLk+PkKstLqSwroX95aXKrSG/lpVRVljG4XxkDK8sZ1K+MQf3KGNK/nMH9yx38zKxPcEAz60bL127j1toV3Da3jvotjYwcWMkR4wbT0ho0tbbR0tpGc2vw4tptbG1soaK0hGMOGM7Jh4zilMNGd/txbIUWEWza3sy6bU2s29rEuq2NrNvWxPptTWxramF7UyvbGlvZ3txCQ1MrO5pbaWxpo7G5jcaWVnakf7c3tdLQ3Eo+/+QMrEzCWvttcP8yBvdLwtvgfuUM7FfGgDTo9UuDX7+yEspKRVlJCaUlSu8L6NgyGbQFtEXQ1pb8jfRx8PpjaC9USMlWJFEiKJEoLUluJYLSkhJKJUpLlfwt6XDrsPy+bC01s+KVaUCTdDrwPaAU+HFEfKPD/JOA7wLTgAsi4vaceROBHwMTSP61fGdELN/ZvhzQbF9qaW3jgcX13DZ3BSs37qC8VJSXlqQ3MXZof956cDVvPmgkVZXF01KWpYigsaWN7U2tbG1sYcuOFrbsaH7t/qbtzWza3szGhub0fhObtjezZUcLm7c3s3lHy2tnqPZkag950mv324Of0gDXHgrbp7UHxeTe69tR+ig3RObu5w1/c5Z9bZnXltVfTaOT5YpZbw++vfvZFZ/pE4by7fdOL+g+dhXQCvqrIakUuAZ4B1AHzJE0OyIW5iz2MvAB4LOdbOIXwNcj4l5JA4HOB4Eyy0BZaQmnTB3NKVNHZ11KjyGJfmmr17Cqij3aRktrW9pil96akta7Hc1ttLQFrW1ttLQGLW3x2lAlHZWINBy93qLVHpDoEHQibVkjIEha3VojaGtLWuJaI9lnaxu0pftsjaC1tY3W4PV5EbS0RtpClyzTFqTbaW/F47X5AUT7PoOclsdI63p9WhDpsm+clrP4a+2Buf8pf30anUz76+WKWo8ocs9Fb3+CRWj8sP6Z7r/Q/62fBSyNiGUAkm4BzgVeC2jtLWKS3hC+JE0FyiLi3nS5rQWu1cx6gLLSEoYMKGEIhR2XzswsS4U+EnccsCLncV06LR8HAxsl/VrSU5KuTlvk3kDSZZJqJdXW19d3Q8lmZmZm2Sp0QOusyzzfdtoy4ESSrs+ZwAEkXaFv3FjEdRFRExE11dXVe1qnmZmZWdEodECrIznAv914YGUX1n0qIpZFRAvwW+Cobq7PzMzMrOgUOqDNAaZI2l9SBXABMLsL6w6T1N4s9jZyjl0zMzMz660KGtDSlq/LgbuBRcCtEbFA0lWSzgGQNFNSHfBe4FpJC9J1W0m6N++T9AxJd+mPClmvmZmZWTHwQLVmZmZmGdjVOGi+noqZmZlZkXFAMzMzMysyvaqLU1I98NI+2NVIYO0+2I91jd+X4uX3pjj5fSlefm+KU3e/L5MiotMxwnpVQNtXJNXurM/YsuP3pXj5vSlOfl+Kl9+b4rQv3xd3cZqZmZkVGQc0MzMzsyLjgLZnrsu6AOuU35fi5femOPl9KV5+b4rTPntffAyamZmZWZFxC5qZmZlZkXFAMzMzMysyDmhdIOl0SYslLZV0Zdb19GWSJki6X9IiSQskfSqdPlzSvZKWpH+HZV1rXySpVNJTkn6fPt5f0l/S9+WXkiqyrrEvkjRU0u2Snku/O8f5O5M9Sf+Y/jv2rKSbJfXzdyYbkn4qaY2kZ3OmdfodUeL7aSaYL+mo7qzFAS1PkkqBa4AzgKnAhZKmZltVn9YCfCYiDgOOBf4hfT+uBO6LiCnAfelj2/c+BSzKefxN4D/T92UD8KFMqrLvAX+MiEOB6STvkb8zGZI0DvgkUBMRRwClwAX4O5OVnwGnd5i2s+/IGcCU9HYZ8MPuLMQBLX+zgKURsSwimoBbgHMzrqnPiohVEfFken8LyQ/NOJL35OfpYj8H3pVNhX2XpPHAmcCP08cC3gbcni7i9yUDkgYDJwE/AYiIpojYiL8zxaAM6C+pDBgArMLfmUxExEPA+g6Td/YdORf4RSQeB4ZKGttdtTig5W8csCLncV06zTImaTLwJuAvwOiIWAVJiANGZVdZn/Vd4HNAW/p4BLAxIlrSx/7uZOMAoB7437T7+ceSqvB3JlMR8QrwbeBlkmC2CZiLvzPFZGffkYLmAge0/KmTaR6jJGOSBgK/Aj4dEZuzrqevk3QWsCYi5uZO7mRRf3f2vTLgKOCHEfEmYBvuzsxcejzTucD+wH5AFUnXWUf+zhSfgv7b5oCWvzpgQs7j8cDKjGoxQFI5STi7MSJ+nU5e3d7EnP5dk1V9fdSbgXMkLSc5DOBtJC1qQ9PuG/B3Jyt1QF1E/CV9fDtJYPN3JlunAC9GRH1ENAO/Bo7H35lisrPvSEFzgQNa/uYAU9IzaypIDuKcnXFNfVZ6XNNPgEUR8Z2cWbOB96f33w/8bl/X1pdFxBciYnxETCb5jvwpIi4C7gfeky7m9yUDEfEqsELSIemktwML8Xcmay8Dx0oakP671v6++DtTPHb2HZkNXJKezXkssKm9K7Q7+EoCXSDpnSStAaXATyPi6xmX1GdJOgF4GHiG1491+iLJcWi3AhNJ/uF7b0R0PODT9gFJbwU+GxFnSTqApEVtOPAUcHFENGZZX18kaQbJyRsVwDLgUpL/qPs7kyFJ/wqcT3J2+lPAh0mOZfJ3Zh+TdDPwVmAksBr4F+C3dPIdSQP1D0jO+mwALo2I2m6rxQHNzMzMrLi4i9PMzMysyDigmZmZmRUZBzQzMzOzIuOAZmZmZlZkHNDMzMzMiowDmpn1OpIeTf9OlvS+bt72Fzvbl5lZd/IwG2bWa+WOxdaFdUojonUX87dGxMDuqM/MbGfcgmZmvY6krendbwAnSpon6R8llUq6WtIcSfMl/X26/Fsl3S/pJpLBj5H0W0lzJS2QdFk67RtA/3R7N+buKx1N/GpJz0p6RtL5Odt+QNLtkp6TdGM6wKWZ2U6V7X4RM7Me60pyWtDSoLUpImZKqgT+LOmedNlZwBER8WL6+IPpaOH9gTmSfhURV0q6PCJmdLKvvwFmANNJRiGfI+mhdN6bgMNJrtP3Z5Jrlj7S/U/XzHoLt6CZWV9yKsm18+aRXBZsBDAlnfdETjgD+KSkp4HHSS6IPIVdOwG4OSJaI2I18CAwM2fbdRHRBswDJnfLszGzXsstaGbWlwj4RETc/YaJybFq2zo8PgU4LiIaJD0A9Mtj2zuTew3FVvxvr5nthlvQzKw32wIMynl8N/AxSeUAkg6WVNXJekOADWk4OxQ4Nmdec/v6HTwEnJ8e51YNnAQ80S3Pwsz6HP8vzsx6s/lAS9pV+TPgeyTdi0+mB+rXA+/qZL0/Ah+VNB9YTNLN2e46YL6kJyPiopzpvwGOA54GAvhcRLyaBjwzsy7xMBtmZmZmRcZdnGZmZmZFxgHNzMzMrMg4oJmZmZkVGQc0MzMzsyLjgGZmZmZWZBzQzMzMzIqMA5qZmZlZkfn/Bvwn3z05guwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ModelAndPlot:\n",
    "    \n",
    "    def __init__(self, X:torch.Tensor, y:torch.Tensor):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def dynamic_fit(self, activation_fun:Union[str,callable]=\"relu\", optimizer:str=\"Adam\", scheduler:str=\"None\",\n",
    "                    loss:Union[str,callable]=\"mse_loss\", n_iter:int=10, lr:float=.1, max_lr=.1):\n",
    "        \n",
    "        self.m = Model(activation_fun=activation_fun, dim_in=self.X.size()[1], dim_out=1)\n",
    "        self.m.to(device)\n",
    "        self.opt = getattr(torch.optim, optimizer)(self.m.parameters(), lr=lr)\n",
    "        self.scheduler = getattr(torch.optim.lr_scheduler, scheduler) if scheduler != \"None\" else None\n",
    "        \n",
    "        if self.scheduler is not None:\n",
    "            try:\n",
    "                self.scheduler = self.scheduler(self.opt, base_lr=lr, max_lr=max_lr, step_size_up=n_iter//2, cycle_momentum=True)                \n",
    "            except ValueError:\n",
    "                self.scheduler = self.scheduler(self.opt, base_lr=lr, max_lr=max_lr, step_size_up=n_iter//2, cycle_momentum=False)\n",
    "        \n",
    "        self._loss = getattr(torch.nn.functional, loss) if isinstance(loss, str) else loss\n",
    "        \n",
    "        self.fit(n_iter)            \n",
    "        self.plot(n_iter, loss, activation_fun, optimizer)\n",
    "        \n",
    "    def fit(self, n_iter):\n",
    "        \n",
    "        self.losses = torch.zeros(n_iter, requires_grad=False)    \n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            y_pred = self.m(self.X)\n",
    "            \n",
    "            l = self._loss(self.y, y_pred)\n",
    "            \n",
    "            self.losses[i] = l.item()\n",
    "            l.backward()\n",
    "            \n",
    "            self.opt.step()\n",
    "            \n",
    "            if self.scheduler is not None: \n",
    "                self.scheduler.step()\n",
    "                \n",
    "            self.opt.zero_grad()\n",
    "            \n",
    "        self.m.eval()\n",
    "        self.y_pred = self.m(X)\n",
    "\n",
    "        \n",
    "    def plot(self, n_iter, loss, activation_fun, optimizer):\n",
    "        fig, ax = plt.subplots(figsize=(10,4))\n",
    "        ax.plot(range(n_iter), self.losses.detach().numpy())\n",
    "        ax.set_xlabel(\"iteration\")\n",
    "        ax.set_ylabel(f\"loss: {loss}\")\n",
    "        ax.set_title(f\"activation: {activation_fun}, optimizer: {optimizer}, n_iter: {n_iter}\")\n",
    "        plt.show()\n",
    "        \n",
    "MAP = ModelAndPlot(X, y)\n",
    "MAP.dynamic_fit(activation_fun=\"relu\", optimizer=\"SGD\", scheduler=\"CyclicLR\", loss=\"mse_loss\", \n",
    "                n_iter=100, lr=.001, max_lr=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30433784c14b4c249ec215c27dc4e341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='activation_fun', options=('relu', 'softplus', 'sigmoid', 'tanh', Nâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAP = ModelAndPlot(X, y)\n",
    "widgets.interact(MAP.dynamic_fit, activation_fun=[\"relu\", \"softplus\", \"sigmoid\", \"tanh\", None], \n",
    "                 optimizer=[\"Adam\", \"RMSprop\"],\n",
    "                 scheduler=[\"None\", \"CyclicLR\"],\n",
    "                 loss=[\"mse_loss\", \"l1_loss\"], \n",
    "                 n_iter=widgets.IntText(value=50), \n",
    "                 lr=widgets.FloatText(value=.01), \n",
    "                 max_lr=widgets.FloatText(value=.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7281194324e4561874846f40d829a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='elev', max=180, min=-180), IntSlider(value=-55, descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dynamic3d_scatter = plotter_wrapper(X, y, y_pred=MAP.y_pred.detach().numpy())\n",
    "widgets.interact(dynamic3d_scatter, elev=(-180,180), azim=(-180,180));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now.look.at.that! Even though the loss trends seems okay the model predictions are clearly not performing in the area where `z` is smaller than zero. Could this have anything to do with the interaction of `z` and the activation function usign for the output (here the rectified linear unit, i.e. `max(0,model(x,y)`)? \n",
    "\n",
    "Actually it does. Switching to a linear output gets closer to the truth and using tanh hits the nail on the head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a 2d surface with a Dense net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a more complex surface and do the same again as above but using multiple neurons and also feed output of neurons into the input of other neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(5e3)\n",
    "dim = 2\n",
    "X = torch.zeros((n,dim))\n",
    "X[:,0].uniform_(-5, 5)\n",
    "X[:,1].uniform_(-5, 5)\n",
    "y = torch.cos(X[:,0])*torch.sin(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee91237b0ce4a86917e054c26e73994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='elev', max=180, min=-180), IntSlider(value=-55, descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dynamic3d_scatter = plotter_wrapper(X, y)\n",
    "widgets.interact(dynamic3d_scatter, elev=(-180,180), azim=(-180,180));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper hyper ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (1): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HyperModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, activation_fun:Union[str,callable]=\"relu\", dim_in:int=2, hidden:List[int]=[5], \n",
    "                 dim_out:int=1, output_fun:Union[str,callable]=\"linear\"):\n",
    "        super().__init__()\n",
    "        self.dense = [torch.nn.Linear(dim_in, hidden[0])]\n",
    "        if len(hidden) > 1:\n",
    "            self.dense += [torch.nn.Linear(hidden[i], hidden[i+1]) for i in range(len(hidden)-1)]\n",
    "        self.dense += [torch.nn.Linear(hidden[-1], dim_out)]\n",
    "        self.dense = torch.nn.ModuleList(self.dense)\n",
    "        self.set_activation(activation_fun)\n",
    "        self.set_output_fun(output_fun)\n",
    "        \n",
    "    def set_activation(self, fun_name):\n",
    "        self.activation = getattr(torch.nn.functional, fun_name) if isinstance(fun_name, str) else fun_name\n",
    "        \n",
    "    def set_output_fun(self, fun_name):\n",
    "        if fun_name == \"linear\":\n",
    "            self.output_fun = lambda x: x\n",
    "        else:\n",
    "            self.output_fun = getattr(torch.nn.functional, fun_name) if isinstance(fun_name, str) else fun_name\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = x.clone()\n",
    "        for i,l in enumerate(self.dense):\n",
    "            if i<len(self.dense):\n",
    "                o = self.activation(l(o))\n",
    "            else:\n",
    "                o = self.output_fun(l(o))\n",
    "        return o.squeeze(1)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "m = HyperModel(activation_fun=\"relu\", dim_in=dim, hidden=[3,2], dim_out=1, output_fun=\"linear\")\n",
    "m.to(device)\n",
    "print(m.dense)\n",
    "m(X).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subclassing `ModelAndPlot` modifying the `dynamic_fit` method since we are dealing with multiple layers here.\n",
    "\n",
    "The way to control the number of neurons per layer and the layers is via the `hidden` argument of the `dynamic_fit` method. If you want 2 hidden layers just specify their individual width (contained numer of neurons) and concatenate them with a comma, like so: \"5,2\" for two hidden layers with the first layer containing 5 neurons and the second layer containing 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_fun linear\n",
      "HyperModel(\n",
      "  (dense): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "    (1): Linear(in_features=5, out_features=2, bias=True)\n",
      "    (2): Linear(in_features=2, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "number of parameters 30 => [torch.Size([5, 2]), torch.Size([5]), torch.Size([2, 5]), torch.Size([2]), torch.Size([1, 2]), torch.Size([1])]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAEWCAYAAADfMRsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcZZ3v8c833Vk6a2dpIekOWTQ4BAhBmwgq4jC5XnAJONdRNhcGB3Uuow4uoMwwDjPOVTJXL84wDrgvLAooRAmClxt1VECCCQlJRGJY0iQhzZJ97eR3/zhPw6GtTldCV9f2fb9e9eo6az2nTlXqm+d5znMUEZiZmZlZ5RtU7gKYmZmZWXEc3MzMzMyqhIObmZmZWZVwcDMzMzOrEg5uZmZmZlXCwc3MzMysSji4mZWZpCMkbZPUUIJ9nyvprv7eb3+Q9JikueUuR0+S/lPS3x/itp+W9NX+LlMtq+TPqFklcnAzG2A9A0tEPBERIyNi30vc71RJIakxt+/rIuJNL2W/tUzS+yT9Mj8vIj4YEf90KPuLiH+JiPf3T+mKJ6lN0i2Snpa0WdJySe/LLR8i6XJJD0vaLulJSXdIelNuncck7ZS0VdImSb+W9EFJJf2d6PkZTZ/hV5TyNSX9U3qPuiR9psDycyQ9nt6rWyWNyy0bJ+mHadnjks4pZVnNenJwM7N+lw+P9tIU+V5+B1gLTAHGA+8Bnsotvxk4I80fC0wDrgLe0mM/b4uIUWk/nwMuAb72Uso/kA7ic7ca+CRwe4F9HA1cA7wbOAzYAfxHbpWrgT1p2bnAl9M2ZgMjIvzww49DeACXAn8AtgIrgbf3WP5XwKrc8leR/cDuB3YC28h+PKYCATQCZwGLe+znb4EF6flbgCXAFrIf6s/k1nsi7WdbepwEvA/4ZW6d1wL3A5vT39fmlv0M+CfgV6nMdwETinwv3gh0kP3QbwC+k+a/FVgKbAJ+DczKbfMYMDc9/ybwzz33dxDn4q/IfoyfBRYAk3LLAvgwsAZ4GphP9p/Wo4BdwL70fm3qWZbccX0S2AisB84E3gz8Pr3ep3Ov9Rngu+n5v+fOxTagq/t8AZOAW4BO4FHgwz32cTPw3XSe31/E8W8DZveybC7Z562tj308fz5y8+aQfV6PKfI8BPBB4BHgObKQoz62ef4zCvwi7WN7OqZ3Ffk5ugRYBuwGGg/ic/Ndct+hNO9fgOtz0y8nC2qjgBHp+ZG55d8BPtff/7744UdvD9e4mR26PwAnA2OAfwS+K2kigKS/IPsBfg8wGpgHPBMR7yYLWG+LrHn0yh77XAC8UtKM3LxzgOvT8+1pn81kIe5Dks5My96Q/janfd+T33Fq7rkd+BJZrcwXgNslje/xWucDLwOGAB/Pbb+sj2ahw4FxZLU1F0p6FfB14APp9a4BFkgaeoB9HDRJpwL/C3gnMBF4HLixx2pvB9rJwvMZwF9GxCqykHFPer+aD3Bcw4BW4HLgK8B5wKvJzv/lkqb33CgiLkr7HQm8nizI3JaaHn8EPJj2+WfARyX999zmZ5CFt2bgOkmvl7TpAG/DvcDVks6SdESPZXOB+yKi4wDbFxQRvyELricfxGZvBU4AjiM7J//9wKu/6PW6P8PHpffue0V+js4m+z40R0SXpP+Q9B8cmqPJzk13mf5ACmvpsS8ifp9b/8G0jdmAcHAzO0QRcVNErIuI/RHxPbJahjlp8fuBKyPi/sisjojHi9jnDuA2sh8iUoD7E7JAR0T8LCKWp9dcBtwAnFJkkd8CPBIR34mIroi4Afgd8LbcOt+IiN9HxE7g+8DsXNlmRcT19G4/8A8RsTtt/1fANRFxX0Tsi4hvkdWInFhkeYt1LvD1iPhtROwGPgWcJGlqbp3PR8SzEfEE8H9I72+R9gKfjYi9ZIFwAnBVRGyNiBXACmBWbxtLagFuBf4mIpaQhZqWiLgiIvZExBqyMHhWbrN7IuLWdJ53RsQvDxAsAf4C+C/g74FHJS2VdEJaNoGsFrS7PONSH7bNknYVcfzryAJ5sT4XEZvSe72I3GfoEBXzOfpSRKxNnzsi4q8j4q8P8fVGktVI520mq3E70DKzAeHgZnaIJL0n/UBuSrUhx5D9SAJMJquROxTX80KwOAe4NQU6JL1G0iJJnZI2k9UYTehlPz1NIquNynucrNan24bc8x1kP1TF6oyIfBCYAnys+/1J79HkVI7+9KLjiohtwDO8+LjW5p4/fpBleCZeuHBkZ/qb7z+2k17eJ0mDyWrOro+I7lrAKcCkHu/Lp8n6TBUqb58i4rmIuDQijk77WQrcKklk78XE3LrPphD4aqCY2s9WsibhYr2Uz1AhxXyODur96sM2slryvNFk3QcOtMxsQDi4mR0CSVPIakkuAsanH8KHAKVV1pL1jSkk+tj9XcAESbPJAly+lut6stq3yRExBvjP3Gv2td91ZD+CeUcAT/axXbF6vv5aspqq5txjeKrp62k7MDw3ffhBvO6LjkvSCLImtfxxTc49PyJtU6jM/e3fyH7U/y43by3waI/3ZVREvDm3ziGXKyKeBv6VLNiMA+4GTpDUdrD7SrV2rcAv+1q3hIr5HPXneVxB1swLQGoGH0rWp/H3QGOPrgzHpW3MBoSDm9mhGUH2Y9EJIOl8shq3bl8FPi7p1cq8IoU9yGpr/qhPVLeI6CKrpZlP9sP709ziUcCzEbFL0hyyGrlunWTNlb3teyFwZBrqoFHSu4CZwI+LOuKD9xXgg6mWUJJGSHqLpELNSkuBN6dmvMOBj+YXSvqmpG/28jrXA+dLmp36Pf0LWZ+ux3LrfELSWEmTgY8A30vznwLaJA055KPshaQPkDVjnxMR+3OLfgNskXSJpCZJDZKOyTVtHsprfT7tozG9vx8CVkfEMxFxF1mT5a3pXAxJNYG9NllLGi3prWRNw9+NiOVp/vskPXao5SxSz+/HwXyOiiJpsKRhZL+BjZKG6YVxFK8D3ibp5PSfgCuAH6Sm8e3AD4ArUjleR9Yf8TuHWhazg+XgZnYIImIl8L+Be8h+aI4luxqze/lNwGfJQsVWsj5O3f2E/hfwd6nZ5+MUdj1Zp/KbUpDr9tdkPxpbyTrKfz/3mjvSa/4q7ftFP8wR8QxZx/GPkTWffRJ4a6qh6ZOkFZLOLWbd9HqLyfon/TtZx/zVZFcQFvIdsk7ej5HVOH6vx/LJ5N7fHq9zN1nfrlvIrvp8OS/uLwZZv8EHyALi7bwwxMX/I6st2SCpqPfhIJxNFkDWKRtgeZukT6dm17eR9f16lOxK16+SXeRSUAoR2w7wWsOBH5JddbmGrAZyXm75n5MF9O+mdR4l6xt4Wo/9/Ch9ttYCl5FdwHJ+bnmv56EffQb4VvoMv/MgP0fA84Mo/+cBVvkKWRP32WTHuZNs+A9Sv8UPkgW4jWT/Wcr3l/troCktuwH4UNrGbEAootQtBWZmhy7Vhj1INgTE3kPYPoAZEbG63wtXZ5Td4eAj6YpcMysDBzczq2kObmZWS9xUamZmJZWaLrcVeByoOdPMCnCNm5mZmVmVcI2bmZmZWZWomxtBT5gwIaZOnVruYpiZmZn16YEHHng6Ilp6zq+b4DZ16lQWL15c7mKYmZmZ9UlSwdskuqnUzMzMrEo4uJmZmZlVCQc3MzMzsyrh4GZmZmZWJRzczMzMzKqEg5uZmZlZlXBwMzMzM6sSdTOOW6ndvmw9T23ZxZxp4zhq4mgaBqncRTIzM7Ma4+DWT+5csYEFD64DYNTQRl49dSwnTB3H3KMO45WHjypz6czMzKwW1M1N5tvb26PUd05Yt2kn9z/2LL95NHs8snEbgxvELR96LbPamkv62mZmZlY7JD0QEe1/NN/BrXQ2bN7Fn//Hr2hsGMSPP/x6Rg8bPKCvb2ZmZtWpt+DmixNK6PAxw/i3c47nyU07+dQty6mXkGxmZmal4eBWYq+eMo6Pv+mV3L58Pd+974lyF8fMzMyqmIPbAPjAG6ZzypEt/NOPV7Ji3eZyF8fMzMyqlIPbABg0SHzhnccxdvhgLrp+Cdt2d5W7SGZmZlaFHNwGyPiRQ7nqrON5/JntXPbD5eUujpmZmVWhkgc3SadJeljSakmXFlh+saSVkpZJulvSlNyyz0t6KD3elZs/TdJ9kh6R9D1JQ0p9HP3hxOnjuejUGdy2dB2r1m8pd3HMzMysypQ0uElqAK4GTgdmAmdLmtljtSVAe0TMAm4GrkzbvgV4FTAbeA3wCUmj0zafB74YETOA54ALSnkc/ek9J01hkGDh8vXlLoqZmZlVmVLXuM0BVkfEmojYA9wInJFfISIWRcSONHkv0JaezwR+HhFdEbEdeBA4TZKAU8lCHsC3gDNLfBz9ZsLIobxm2nhuX77ew4OYmZnZQSl1cGsF1uamO9K83lwA3JGePwicLmm4pAnAnwKTgfHApojo7uHf6z4lXShpsaTFnZ2dL+Ew+tebZ01kTed2fv/UtnIXxczMzKpIqYNboTutF6xmknQe0A7MB4iIu4CFwK+BG4B7gK6D2WdEXBsR7RHR3tLScvClL5HTjj4cCW53c6mZmZkdhFIHtw6yWrJubcC6nitJmgtcBsyLiN3d8yPisxExOyL+G1lgewR4GmiW1HigfVayllFDmTN1nPu5mZmZ2UEpdXC7H5iRrgIdApwFLMivIOl44Bqy0LYxN79B0vj0fBYwC7grso5hi4B3pFXfC9xW4uPod2+ZNZHVG7fxyFNby10UMzMzqxIlDW6pH9pFwJ3AKuD7EbFC0hWS5qXV5gMjgZskLZXUHewGA/8laSVwLXBerl/bJcDFklaT9Xn7WimPoxROO8bNpWZmZnZwVC9XNra3t8fixYvLXYwXeec197Bpxx7u+ttTyl0UMzMzqyCSHoiI9p7zfeeEMnrzMYfz+6e2sXqjm0vNzMysbw5uZXT6sRORYOHyDeUuipmZmVUBB7cyOmz0MNqnjPXVpWZmZlYUB7cyO/2Yifxuw1b+0OnBeM3MzOzAHNzK7PRjDwfgDte6mZmZWR8c3Mps4pgmXj1lLLe7n5uZmZn1wcGtApx+zOGsWr+Fx5/ZXu6imJmZWQVzcKsAbzgyu4/qA48/V+aSmJmZWSVzcKsAL28ZSdPgBpZ1bC53UczMzKyCObhVgIZB4uhJo3noSQc3MzMz652DW4U4tm0MK9ZtYd/++rgFmZmZmR08B7cKcWzrGHbu3efx3MzMzKxXDm4VYlbbGAD3czMzM7NeObhViGkTRjJ8SIP7uZmZmVmvHNwqRMMgccykMSzr2FTuopiZmVmFcnCrIMe0jmHl+i107dtf7qKYmZlZBXJwqyCz2sawa+9+VvsCBTMzMyvAwa2CHNOaXaCw3BcomJmZWQEObhVk+oQRjBjSwHJfoGBmZmYFOLhVkEGDxNGtYxzczMzMrCAHtwozq3UMK9f5AgUzMzP7YyUPbpJOk/SwpNWSLi2w/GJJKyUtk3S3pCm5ZVdKWiFplaQvSVKa/7O0z6Xp8bJSH8dAObZtDLu79vPIRl+gYGZmZi9W0uAmqQG4GjgdmAmcLWlmj9WWAO0RMQu4Gbgybfta4HXALOAY4ATglNx250bE7PTYWMrjGEjH+gIFMzMz60Wpa9zmAKsjYk1E7AFuBM7IrxARiyJiR5q8F2jrXgQMA4YAQ4HBwFMlLm/ZTR0/glFDG93PzczMzP5IqYNbK7A2N92R5vXmAuAOgIi4B1gErE+POyNiVW7db6Rm0r/vbkLtSdKFkhZLWtzZ2flSjmPAZBcojGaZg5uZmZn1UOrgVihQRcEVpfOAdmB+mn4FcBRZDVwrcKqkN6TVz42IY4GT0+PdhfYZEddGRHtEtLe0tLykAxlIs9qaWbV+C3t9gYKZmZnllDq4dQCTc9NtwLqeK0maC1wGzIuI3Wn224F7I2JbRGwjq4k7ESAinkx/twLXkzXJ1oxjWsewp2s/v39qa7mLYmZmZhWk1MHtfmCGpGmShgBnAQvyK0g6HriGLLTlLzJ4AjhFUqOkwWQXJqxK0xPStoOBtwIPlfg4BtSsdIHCQ24uNTMzs5ySBreI6AIuAu4EVgHfj4gVkq6QNC+tNh8YCdyU+qx1B7ubgT8Ay4EHgQcj4kdkFyrcKWkZsBR4EvhKKY9joE0ZP5xRwxpZ5itLzczMLKex1C8QEQuBhT3mXZ57PreX7fYBHygwfzvw6n4uZkWRxLG+g4KZmZn14DsnVKhjW8fwu/Vb2dPlCxTMzMws4+BWoY5tG8Oefb5AwczMzF7g4Fahjp6UXaCwcv2WMpfEzMzMKoWDW4WaPLaJwQ3i0ae3l7soZmZmViEc3CpUY8Mgjhg3nEc7HdzMzMws4+BWwaZNGOkaNzMzM3ueg1sFm94ygkef2c7+/QXvEmZmZmZ1xsGtgk2fMII9Xft5ctPOchfFzMzMKoCDWwWbNmEEgJtLzczMDHBwq2jTWhzczMzM7AUObhWsZeRQRg5tdHAzMzMzwMGtokliessI/tC5rdxFMTMzswrg4Fbhpk0Y4Ro3MzMzAxzcKt60CSN4ctNOdu3dV+6imJmZWZk5uFW4aRNGEAFPPLuj3EUxMzOzMnNwq3AvbxkJwBr3czMzM6t7Dm4Vbmoay22N+7mZmZnVPQe3CjdyaCMvGzXUN5s3MzOz4oKbpNdJGpGenyfpC5KmlLZo1s1XlpqZmRkUX+P2ZWCHpOOATwKPA98uWansRaa3jHRTqZmZmRUd3LoiIoAzgKsi4ipgVDEbSjpN0sOSVku6tMDyiyWtlLRM0t35mjxJV0paIWmVpC9JUpr/aknL0z6fn1+rpk8YwbPb97Bpx55yF8XMzMzKqNjgtlXSp4DzgNslNQCD+9oorXc1cDowEzhb0sweqy0B2iNiFnAzcGXa9rXA64BZwDHACcApaZsvAxcCM9LjtCKPoyr5ZvNmZmYGxQe3dwG7gQsiYgPQCswvYrs5wOqIWBMRe4AbyWrtnhcRiyKie5Cye4G27kXAMGAIMJQsKD4laSIwOiLuSbWA3wbOLPI4qpJvNm9mZmZwEDVuZE2k/yXpSGA2cEMR27UCa3PTHWleby4A7gCIiHuARcD69LgzIlal7TuK2aekCyUtlrS4s7OziOJWpiPGDadhkFjjK0vNzMzqWrHB7RfAUEmtwN3A+cA3i9iuUN+zKLiidB7QTqrJk/QK4CiyGrhW4FRJbziYfUbEtRHRHhHtLS0tRRS3Mg1uGMQR44a7xs3MzKzOFRvclJoz/xz4t4h4O3B0Edt1AJNz023Auj/auTQXuAyYFxG70+y3A/dGxLaI2EZWE3di2mdbbvOC+6w10yaM8JWlZmZmda7o4CbpJOBc4PY0r6GI7e4HZkiaJmkIcBawoMeOjweuIQttG3OLngBOkdQoaTDZhQmrImI92cUSJ6arSd8D3FbkcVStaRNG8NjT29m/v2DlopmZmdWBYoPbR4FPAT+MiBWSppP1PzugiOgCLgLuBFYB30/bXyFpXlptPjASuEnSUkndwe5m4A/AcuBB4MGI+FFa9iHgq8DqtM4dRR5H1ZreMoKde/exYcuuchfFzMzMyqSxmJUi4ufAzyWNkjQyItYAHy5y24XAwh7zLs89n9vLdvuAD/SybDHZECF1Iz8kyKTmpjKXxszMzMqh2FteHStpCfAQsFLSA5KK6eNm/WT6hJGAbzZvZmZWz4ptKr0GuDgipkTEEcDHgK+UrljW02GjhzJ8SINvNm9mZlbHig1uIyLi+T5tEfEzYERJSmQFSUpXlm4rd1HMzMysTIoNbmsk/b2kqenxd8CjpSyY/bFpE0Z4LDczM7M6Vmxw+0ugBfgB8MP0/PxSFcoKmz5hBGuf3cGerv3lLoqZmZmVQbFXlT5HkVeRWulMaxnB/oAnnt3BK142stzFMTMzswF2wOAm6Uf0cjspgIiY19sy63/PX1nauc3BzczMrA71VeP2rwNSCivK1NxYbmZmZlZ/Dhjc0sC7fZJ0S0T8j/4pkvVmTNNgxjQN5slNO8tdFDMzMyuDYi9O6Mv0ftqP9aG1uYmO5xzczMzM6lF/BTff+XyAtI1t4kkHNzMzs7rUX8HNBkjr2CY6nttBhLOymZlZvemv4KZ+2o/1oW3scLbv2cemHXvLXRQzMzMbYEUHN0lNkl7Zy+JL+qk81ofW5iYAX6BgZmZWh4oKbpLeBiwFfpKmZ0ta0L08Iu4qTfGsp7axWXDreG5HmUtiZmZmA63YGrfPAHOATQARsRSYWpoi2YG8ENxc42ZmZlZvig1uXRGxuaQlsaKMaRrMyKGNDm5mZmZ1qKh7lQIPSToHaJA0g+y+pb8uXbGsN5JobW5yHzczM7M6VGyN298ARwO7gRuALcBHS1UoO7C2sR6E18zMrB4VVeMWETuAy4DLJDUAIyJiV0lLZr1qHdvE/Y89W+5imJmZ2QAr9qrS6yWNljQCWAE8LOkTpS2a9aZtbBNbdnWxZZfHcjMzM6snxTaVzoyILcCZwELgCODdxWwo6TRJD0taLenSAssvlrRS0jJJd0uakub/qaSluccuSWemZd+U9Ghu2ewij6MmtDYPB/Ctr8zMzOpMscFtsKTBZMHttojYSxH3J03NqlcDpwMzgbMlzeyx2hKgPSJmATcDVwJExKKImB0Rs4FTgR1Afry4T3QvT8OT1A0PCWJmZlafig1u1wCPASOAX6RasS1FbDcHWB0RayJiD3AjcEZ+hRTQukeTvRdoK7CfdwB35Nara60puD3pQXjNzMzqSlHBLSK+FBGtEfHmyDwO/GkRm7YCa3PTHWleby4A7igw/yyyq1nzPpuaV78oaWihnUm6UNJiSYs7OzuLKG51GD9iCMMGD3KNm5mZWZ0p6qpSSc3Ae8julpDf5sN9bVpgXsEmVknnAe3AKT3mTwSOBe7Mzf4UsAEYAlxLdq/UK/7ohSKuTctpb2/vs2m3WngsNzMzs/pU7AC8C8maMZcD+w9i/x3A5Nx0G7Cu50qS5pINN3JKROzusfidwA9TvzoAImJ9erpb0jeAjx9EmWpC29jhrnEzMzOrM8UGt2ERcfEh7P9+YIakacCTZE2e5+RXkHQ8WR+60yJiY4F9nE1Ww5bfZmJErJcksgsmHjqEslW1trFNLOvYVO5imJmZ2QAqNrh9R9JfAT8mu3sCABFxwFFgI6JL0kVkzZwNwNcjYoWkK4DFEbEAmA+MBG7KchhPRMQ8AElTyWrsft5j19dJaiFril0KfLDI46gZrWObeG7HXrbv7mLE0GJPo5mZmVWzYn/x95AFrMt4oY9aANP72jAiFpI1tebnXZ57PvcA2z5GgYsZIuLUYgpdy9rGprHcNu3kyMNGlbk0ZmZmNhCKDW4XA6+IiKdLWRgrXmtz95AgDm5mZmb1othx3FaQDYBrFWLy84Pw+rSYmZnVi2Jr3PYBSyUt4sV93PoaDsRKZMLIoQxpGESHhwQxMzOrG8UGt1vTwyrEoEGidWyThwQxMzOrI0UFt4j4VqkLYgevtbnJN5o3MzOrI8X2cbMK1OYaNzMzs7ri4FbFWpubeHrbbnbt3VfuopiZmdkAcHCrYm3j0pAgvkDBzMysLhQd3CRdeKBpG3itzWkQXjeXmpmZ1YWDqXFTH9M2wNqeH8vNwc3MzKweFB3cIuKaA03bwDts9DAaB4knN3kQXjMzs3pQVHCT9BFJo5X5mqTfSnpTqQtnB9YwSExsHuYaNzMzszpRbI3bX0bEFuBNQAtwPvC5kpXKitba7CFBzMzM6kWxwa27P9ubgW9ExIO4j1tFaBs73BcnmJmZ1Ylig9sDku4iC253ShoF7C9dsaxYbWObeGrrLvZ0+XSYmZnVumLvVXoBMBtYExE7JI0jay61MmttbiIC1m/eyZTxI8pdHDMzMyuhYmvcTgIejohNks4D/g7YXLpiWbHaxmZjubmfm5mZWe0rNrh9Gdgh6Tjgk8DjwLdLViorWvdYbu7nZmZmVvuKDW5dERHAGcBVEXEVMKp0xbJiHT5mGIMEHc95LDczM7NaV2wft62SPgW8GzhZUgMwuHTFsmINbhjE4aOH0eH7lZqZmdW8Ymvc3gXsJhvPbQPQCswvZkNJp0l6WNJqSZcWWH6xpJWSlkm6W9KUNP9PJS3NPXZJOjMtmybpPkmPSPqepCFFHkdNmtTcxDoHNzMzs5pXVHBLYe06YIyktwK7IqLPPm6pZu5q4HRgJnC2pJk9VlsCtEfELOBm4Mr0mosiYnZEzAZOBXYAd6VtPg98MSJmAM+RXfVat7LgtqvcxTAzM7MSK/aWV+8EfgP8BfBO4D5J7yhi0znA6ohYExF7gBvJ+sk9LwW07g5a9wJtBfbzDuCONBSJyILczWnZt4AzizmOWtU6ton1m3eyf3+UuyhmZmZWQsX2cbsMOCEiNgJIagH+Ly+Ep960Amtz0x3Aaw6w/gXAHQXmnwV8IT0fD2yKiK7cPlv7KEdNm9TcxN59Qee23Rw2eli5i2NmZmYlUmwft0HdoS15pshtC90Wq2C1UBofrp0efeckTQSOBe48hH1eKGmxpMWdnZ1FFLc6tTZnYe1J93MzMzOracUGt59IulPS+yS9D7gdWFjEdh3A5Nx0G7Cu50qS5pLV6s2LiN09Fr8T+GFE7E3TTwPNkrprCwvuEyAiro2I9ohob2lpKaK41WlSczaWmy9QMDMzq23FXpzwCeBaYBZwHHBtRFxSxKb3AzPSVaBDyJo8F+RXkHQ8cA1ZaNtYYB9nAzfkyhLAIrJ+bwDvBW4r5jhqVauDm5mZWV0oto8bEXELcMvB7DwiuiRdRNbM2QB8PSJWSLoCWBwRC8iaRkcCN2XXHfBERMwDkDSVrMbu5z12fQlwo6R/Jrsq9WsHU65aM2rYYEYNa/SVpWZmZjXugMFN0lYK9x8TWeXX6L5eICIW0qNZNSIuzz2fe4BtH6PAhQcRsYbsilVLWpubfL9SMzOzGnfA4BYRvq1VlfAgvGZmZrWv2IsTrMK1NjexbrODm5mZWS1zcKsRk5qb2LRjL9t3d/W9spmZmVUlB7caMSmN5ebmUjMzs9rl4FYjuocE8SC8ZmZmtcvBrUa0ju0ey81DgpiZmdUqB7ca8bJRw2gYJDeVmpmZ1XED2FEAAA3gSURBVDAHtxrRMEgcPnqYg5uZmVkNc3CrIa3NTXQ4uJmZmdUsB7ca0jrWg/CamZnVMge3GjKpeRgbNu9i3/5CdykzMzOzaufgVkMmNTfRtT/o3Lq73EUxMzOzEnBwqyGTnh/LbUeZS2JmZmal4OBWQ14YhNdjuZmZmdUiB7ca0l3j5gsUzMzMapODWw0ZObSRMU2DHdzMzMxqlINbjZnU7CFBzMzMapWDW41pbR5Gx3MObmZmZrXIwa3GtLrGzczMrGY5uNWYSc1NbNnVxdZde8tdFDMzM+tnDm41pvvK0vWbPSSImZlZrSl5cJN0mqSHJa2WdGmB5RdLWilpmaS7JU3JLTtC0l2SVqV1pqb535T0qKSl6TG71MdRLZ4fhNf93MzMzGpOSYObpAbgauB0YCZwtqSZPVZbArRHxCzgZuDK3LJvA/Mj4ihgDrAxt+wTETE7PZaW7CCqTNvY7kF4HdzMzMxqTalr3OYAqyNiTUTsAW4EzsivEBGLIqL7Hk33Am0AKeA1RsRP03rbcutZL1pGDmVwg3yBgpmZWQ0qdXBrBdbmpjvSvN5cANyRnh8JbJL0A0lLJM1PNXjdPpuaV78oaWihnUm6UNJiSYs7OztfynFUjUGDxOFjhjm4mZmZ1aBSBzcVmBcFV5TOA9qB+WlWI3Ay8HHgBGA68L607FPAn6T544BLCu0zIq6NiPaIaG9paTnEQ6g+k8Y0uanUzMysBpU6uHUAk3PTbcC6nitJmgtcBsyLiN25bZekZtYu4FbgVQARsT4yu4FvkDXJWtI6tol1vtG8mZlZzSl1cLsfmCFpmqQhwFnAgvwKko4HriELbRt7bDtWUndV2anAyrTNxPRXwJnAQyU9iirT2tzEhi276Nq3v9xFMTMzs35U0uCWasouAu4EVgHfj4gVkq6QNC+tNh8YCdyUhvZYkLbdR9ZMerek5WTNrl9J21yX5i0HJgD/XMrjqDaTmpvYtz/YuHV33yubmZlZ1Wgs9QtExEJgYY95l+eezz3Atj8FZhWYf2p/lrHWdI/ltm7Tzuefm5mZWfXznRNqUGuzx3IzMzOrRQ5uNWhS8zDAwc3MzKzWOLjVoOFDGhk7fLDHcjMzM6sxDm41qnVsE2ufdXAzMzOrJQ5uNerIw0bxuw1byl0MMzMz60cObjVq5sTRPLVlN09v85AgZmZmtcLBrUbNnDQagFXrXetmZmZWKxzcatTMiVlwW7nOwc3MzKxWOLjVqObhQ2htbmKla9zMzMxqhoNbDTtq4mjXuJmZmdUQB7caNnPSaP7QuY1de/eVuyhmZmbWDxzcatjMiaPZH/Dwhq3lLoqZmZn1Awe3GnZ0urLU/dzMzMxqg4NbDWsb28SooY3u52ZmZlYjHNxqmCSOmjTaNW5mZmY1wsGtxs2cOJpV67ewf3+UuyhmZmb2Ejm41biZk0azY88+Hntme7mLYmZmZi+Rg1uNe/4OCm4uNTMzq3oObjVuxmEjaRwkX6BgZmZWAxzcatzQxgZe8bKRrnEzMzOrAQ5udWDmJN/6yszMrBaUPLhJOk3Sw5JWS7q0wPKLJa2UtEzS3ZKm5JYdIekuSavSOlPT/GmS7pP0iKTvSRpS6uOoZjMnjmbj1t10bt1d7qKYmZnZS1DS4CapAbgaOB2YCZwtaWaP1ZYA7RExC7gZuDK37NvA/Ig4CpgDbEzzPw98MSJmAM8BF5TuKKrfzHQHhVVuLjUzM6tqpa5xmwOsjog1EbEHuBE4I79CRCyKiB1p8l6gDSAFvMaI+Glab1tE7JAk4FSykAfwLeDMEh9HVfOVpWZmZrWh1MGtFVibm+5I83pzAXBHen4ksEnSDyQtkTQ/1eCNBzZFRFdf+5R0oaTFkhZ3dna+pAOpZs3Dh9Da3OR+bmZmZlWu1MFNBeYVHMJf0nlAOzA/zWoETgY+DpwATAfedzD7jIhrI6I9ItpbWloOruQ15qiJvvWVmZlZtSt1cOsAJuem24B1PVeSNBe4DJgXEbtz2y5JzaxdwK3Aq4CngWZJjQfap73YzEmjWdO5jZ179pW7KGZmZnaISh3c7gdmpKtAhwBnAQvyK0g6HriGLLRt7LHtWEndVWWnAisjIoBFwDvS/PcCt5XwGGrCzImj2R/w8FNby10UMzMzO0QlDW6ppuwi4E5gFfD9iFgh6QpJ89Jq84GRwE2SlkpakLbdR9ZMerek5WRNpF9J21wCXCxpNVmft6+V8jhqwdHpylL3czMzM6tejX2v8tJExEJgYY95l+eezz3Atj8FZhWYv4bsilUrUtvYJkYNa2Tl+s3lLoqZmZkdIt85oU5IYubE0fx05VPc8kAHu/a6r5uZmVm1cXCrIx/5sxkMH9LIx256kDmf/b98ZsEKfrfBTadmZmbVQllf/9rX3t4eixcvLncxyi4iuHfNs9zwmyf4yUMb2LNvP1PGD2dIgzO8mZlZMa57/2t42ehhJX0NSQ9ERHvP+SXv42aVRRInvXw8J718PM9u38MPftvBkic2EYWHwjMzM7MeGgYVGlJ2YDi41bFxI4bw/pOnl7sYZmZmViS3j5mZmZlVCQc3MzMzsyrh4GZmZmZWJRzczMzMzKqEg5uZmZlZlXBwMzMzM6sSDm5mZmZmVcLBzczMzKxK1M0tryR1Ao+X+GUmAE+X+DXs0PjcVCafl8rlc1OZfF4qUynOy5SIaOk5s26C20CQtLjQfcWs/HxuKpPPS+XyualMPi+VaSDPi5tKzczMzKqEg5uZmZlZlXBw61/XlrsA1iufm8rk81K5fG4qk89LZRqw8+I+bmZmZmZVwjVuZmZmZlXCwc3MzMysSji49RNJp0l6WNJqSZeWuzz1StJkSYskrZK0QtJH0vxxkn4q6ZH0d2y5y1qPJDVIWiLpx2l6mqT70nn5nqQh5S5jPZLULOlmSb9L352T/J0pP0l/m/4de0jSDZKG+TtTHpK+LmmjpIdy8wp+R5T5UsoDyyS9qj/L4uDWDyQ1AFcDpwMzgbMlzSxvqepWF/CxiDgKOBH4n+lcXArcHREzgLvTtA28jwCrctOfB76YzstzwAVlKZVdBfwkIv4EOI7sHPk7U0aSWoEPA+0RcQzQAJyFvzPl8k3gtB7zevuOnA7MSI8LgS/3Z0Ec3PrHHGB1RKyJiD3AjcAZZS5TXYqI9RHx2/R8K9kPUCvZ+fhWWu1bwJnlKWH9ktQGvAX4apoWcCpwc1rF56UMJI0G3gB8DSAi9kTEJvydqQSNQJOkRmA4sB5/Z8oiIn4BPNtjdm/fkTOAb0fmXqBZ0sT+KouDW/9oBdbmpjvSPCsjSVOB44H7gMMiYj1k4Q54WflKVrf+D/BJYH+aHg9sioiuNO3vTXlMBzqBb6Rm7K9KGoG/M2UVEU8C/wo8QRbYNgMP4O9MJentO1LSTODg1j9UYJ7HWSkjSSOBW4CPRsSWcpen3kl6K7AxIh7Izy6wqr83A68ReBXw5Yg4HtiOm0XLLvWXOgOYBkwCRpA1wfXk70zlKem/bQ5u/aMDmJybbgPWlaksdU/SYLLQdl1E/CDNfqq7qjr93Viu8tWp1wHzJD1G1pXgVLIauObUDAT+3pRLB9AREfel6ZvJgpy/M+U1F3g0IjojYi/wA+C1+DtTSXr7jpQ0Ezi49Y/7gRnpap8hZB1IF5S5THUp9Zv6GrAqIr6QW7QAeG96/l7gtoEuWz2LiE9FRFtETCX7fvy/iDgXWAS8I63m81IGEbEBWCvplWnWnwEr8Xem3J4ATpQ0PP271n1e/J2pHL19RxYA70lXl54IbO5uUu0PvnNCP5H0ZrIahAbg6xHx2TIXqS5Jej3wX8ByXuhL9Wmyfm7fB44g+wfxLyKiZ0dTGwCS3gh8PCLeKmk6WQ3cOGAJcF5E7C5n+eqRpNlkF40MAdYA55P9x97fmTKS9I/Au8iull8CvJ+sr5S/MwNM0g3AG4EJwFPAPwC3UuA7koL2v5NdhboDOD8iFvdbWRzczMzMzKqDm0rNzMzMqoSDm5mZmVmVcHAzMzMzqxIObmZmZmZVwsHNzMzMrEo4uJlZXZH06/R3qqRz+nnfny70WmZm/cXDgZhZXcqPJ3cQ2zRExL4DLN8WESP7o3xmZoW4xs3M6oqkbenp54CTJS2V9LeSGiTNl3S/pGWSPpDWf6OkRZKuJxvYGUm3SnpA0gpJF6Z5nwOa0v6uy79WGkF9vqSHJC2X9K7cvn8m6WZJv5N0XRq808ysoMa+VzEzq0mXkqtxSwFsc0ScIGko8CtJd6V15wDHRMSjafov0wjpTcD9km6JiEslXRQRswu81p8Ds4HjyEZev1/SL9Ky44Gjye5l+Cuy+7r+sv8P18xqgWvczMwybyK7v+BSslukjQdmpGW/yYU2gA9LehC4l+xm0jM4sNcDN0TEvoh4Cvg5cEJu3x0RsR9YCkztl6Mxs5rkGjczs4yAv4mIO180M+sLt73H9FzgpIjYIelnwLAi9t2b/H0m9+F/l83sAFzjZmb1aiswKjd9J/AhSYMBJB0paUSB7cYAz6XQ9ifAiblle7u37+EXwLtSP7oW4A3Ab/rlKMysrvh/dmZWr5YBXanJ85vAVWTNlL9NFwh0AmcW2O4nwAclLQMeJmsu7XYtsEzSbyPi3Nz8HwInAQ8CAXwyIjak4GdmVjQPB2JmZmZWJdxUamZmZlYlHNzMzMzMqoSDm5mZmVmVcHAzMzMzqxIObmZmZmZVwsHNzMzMrEo4uJmZmZlVif8PxPZxxN3ZIEEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HyperModelAndPlot(ModelAndPlot):\n",
    "    \n",
    "    def __init__(self, X:torch.Tensor, y:torch.Tensor):\n",
    "        super().__init__(X, y)\n",
    "        \n",
    "    def dynamic_fit(self, activation_fun:Union[str,callable]=\"relu\", optimizer:str=\"Adam\", scheduler:str=\"CyclicLR\",\n",
    "                    loss:Union[str,callable]=\"mse_loss\", n_iter:int=10, lr:float=.1, max_lr=.1, \n",
    "                    hidden:str=\"5,2\", output_fun:Union[str,callable]=\"linear\"):\n",
    "        \n",
    "        _hidden = [int(v) for v in hidden.split(\",\")]\n",
    "        assert all([v>0] for v in _hidden), \"The number of neurons in each layer needs to be at least 1\"\n",
    "        print(\"output_fun\", output_fun)\n",
    "        self.m = HyperModel(activation_fun=activation_fun, dim_in=self.X.size()[1], hidden=_hidden, dim_out=1,\n",
    "                            output_fun=output_fun)\n",
    "        print(self.m)\n",
    "        print(f\"number of parameters {sum([np.prod(v.size()) for v in self.m.parameters()])} => {[v.size() for v in self.m.parameters()]}\")\n",
    "        self.m.to(device)\n",
    "        self.opt = getattr(torch.optim, optimizer)(self.m.parameters(), lr=lr)\n",
    "        self.scheduler = getattr(torch.optim.lr_scheduler, scheduler) if scheduler != \"None\" else None\n",
    "        \n",
    "        if self.scheduler is not None:\n",
    "            try:\n",
    "                self.scheduler = self.scheduler(self.opt, base_lr=lr, max_lr=max_lr, step_size_up=n_iter//2, cycle_momentum=True)                \n",
    "            except ValueError:\n",
    "                self.scheduler = self.scheduler(self.opt, base_lr=lr, max_lr=max_lr, step_size_up=n_iter//2, cycle_momentum=False)\n",
    "        \n",
    "        self._loss = getattr(torch.nn.functional, loss) if isinstance(loss, str) else loss\n",
    "        \n",
    "        self.fit(n_iter)            \n",
    "        self.plot(n_iter, loss, activation_fun, optimizer)\n",
    "        \n",
    "        \n",
    "MAP = HyperModelAndPlot(X, y)\n",
    "MAP.dynamic_fit(activation_fun=\"relu\", optimizer=\"SGD\", scheduler=\"CyclicLR\", loss=\"mse_loss\", \n",
    "                n_iter=100, lr=.001, max_lr=.1, hidden=\"5,2\", output_fun=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af37f7dc06b744b4bca637bc1f56a953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='activation_fun', options=('relu', 'softplus', 'sigmoid', 'tanh'), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_s = (y-y.min())/y.std() # standardizing\n",
    "\n",
    "MAP = HyperModelAndPlot(X, y_s)\n",
    "widgets.interact(MAP.dynamic_fit, \n",
    "                 activation_fun=[\"relu\", \"softplus\", \"sigmoid\", \"tanh\"], \n",
    "                 output_fun=[\"relu\", \"softplus\", \"sigmoid\", \"tanh\", \"linear\"],\n",
    "                 optimizer=[\"Adam\", \"RMSprop\"],\n",
    "                 scheduler=[\"None\", \"CyclicLR\"], hidden=widgets.Combobox(value=\"100,5\"),\n",
    "                 loss=[\"mse_loss\", \"l1_loss\"], n_iter=widgets.IntText(value=200), \n",
    "                 lr=widgets.FloatText(value=.01), max_lr=widgets.FloatText(value=.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae5526819fe45fd89cbd40e9a22ec7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='elev', max=180, min=-180), IntSlider(value=-55, descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dynamic3d_scatter = plotter_wrapper(X, y_s, y_pred=MAP.y_pred.detach().numpy())\n",
    "widgets.interact(dynamic3d_scatter, elev=(-180,180), azim=(-180,180));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37_fastai]",
   "language": "python",
   "name": "conda-env-py37_fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
